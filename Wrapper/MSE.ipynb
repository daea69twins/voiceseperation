{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9389d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for custom model would be MSE compared to the original convtasnet\n",
    "# would have no noise overlapped\n",
    "# could be for two, three, or more audio overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f26d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# have two clean audio samples from two different speakers\n",
    "# overlap the two clean voices with each other\n",
    "# overlap the combined audio with noise\n",
    "# run that noise + combined audio through our wrapper\n",
    "# take the first audio stream and the first original audio sample and compare them frame by frame\n",
    "# find the MSE of the frame differences\n",
    "# do the same for the second stream and the second clean audio sample\n",
    "\n",
    "# MSE = the difference between each frame squared / number of frames\n",
    "\n",
    "# MSE changing over time\n",
    "\n",
    "# get MSE before noise reduce and normalization\n",
    "\n",
    "# get MSE before normalization\n",
    "\n",
    "# get MSE after everything to show it got better\n",
    "\n",
    "# 3 male-male, 3 female-female, 3 male-female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57e6e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import noisereduce as nr\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "from pydub import AudioSegment\n",
    "import soundfile as sf\n",
    "from torch import hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa07b804",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'C:/Users/eholy/Desktop/SD/git/voiceseperation/Wrapper/'\n",
    "\n",
    "# these are all 30 minutes, take the second 4 seconds\n",
    "male1fp = 'C:/Users/eholy/Desktop/SD/vox1/mergedWaves/id10020_merged.wav'\n",
    "male2fp = 'C:/Users/eholy/Desktop/SD/vox1/mergedWaves/id10254_merged.wav'\n",
    "male3fp = 'C:/Users/eholy/Desktop/SD/vox1/mergedWaves/id10786_merged.wav'\n",
    "female1fp = 'C:/Users/eholy/Desktop/SD/vox1/mergedWaves/id10343_merged.wav' \n",
    "female2fp = 'C:/Users/eholy/Desktop/SD/vox1/mergedWaves/id10997_merged.wav'\n",
    "female3fp = 'C:/Users/eholy/Desktop/SD/vox1/mergedWaves/id11022_merged.wav'\n",
    "\n",
    "noisefp = 'C:/Users/eholy/Desktop/SD/git/voiceseperation/Filters/Audio Samples/Plane1.mp3'\n",
    "\n",
    "frame_rate = 20050\n",
    "num_frames = frame_rate * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be761d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load audio files\n",
    "\n",
    "male1, _ = librosa.load(male1fp)\n",
    "male2, _ = librosa.load(male2fp)\n",
    "male3, _ = librosa.load(male3fp)\n",
    "female1, _ = librosa.load(female1fp) \n",
    "female2, _ = librosa.load(female2fp)\n",
    "female3, _ = librosa.load(female3fp)\n",
    "\n",
    "noise, _ = librosa.load(noisefp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9c1f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncate clips\n",
    "\n",
    "male1 = male1[num_frames:(num_frames*2)]\n",
    "male2 = male2[num_frames:(num_frames*2)]\n",
    "male3 = male3[num_frames:(num_frames*2)]\n",
    "female1 = female1[num_frames:(num_frames*2)]\n",
    "female2 = female2[num_frames:(num_frames*2)]\n",
    "female3 = female3[num_frames:(num_frames*2)]\n",
    "\n",
    "noise = noise[num_frames:(num_frames*2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ce3adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add noise\n",
    "\n",
    "male1n = np.array(sum([male1, noise])/2 # male 1 + male 2\n",
    "male2n = np.array(sum([male1, noise])/2 # male 1 + male 3\n",
    "male3n = np.array(sum([male2, noise])/2 # male 2 + male 3\n",
    "\n",
    "female1n = np.array(sum([female1, noise])/2 # fe 1 + fe 2\n",
    "female2n = np.array(sum([female1, noise])/2 # fe 1 + fe 3\n",
    "female3n = np.array(sum([female2, noise])/2 # fe 2 + fe 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45009188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlay audio clips\n",
    "mm1 = np.array(sum([male1n, male2n])/2 # male 1 + male 2\n",
    "mm2 = np.array(sum([male1n, male3n])/2 # male 1 + male 3\n",
    "mm3 = np.array(sum([male2n, male3n])/2 # male 2 + male 3\n",
    "\n",
    "ff1 = np.array(sum([female1n, male2n])/2 # fe 1 + fe 2\n",
    "ff2 = np.array(sum([female1n, male3n])/2 # fe 1 + fe 3\n",
    "ff3 = np.array(sum([female2n, male3n])/2 # fe 2 + fe 3\n",
    "\n",
    "fm1 = np.array(sum([female1n, male1n])/2 # fe 1 + male 1\n",
    "fm2 = np.array(sum([female2n, male2n])/2 # fe 2 + male 2\n",
    "fm3 = np.array(sum([female3n, male3n])/2 # fe 3 + male 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf67c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
