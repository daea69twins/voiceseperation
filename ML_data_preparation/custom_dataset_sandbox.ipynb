{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b21151",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The goal is to take the original code from the asteroid library for an inherited, custom Dataset object \n",
    "and fit it to our needs.\n",
    "\n",
    "Original code:\n",
    "https://github.com/daea69twins/voiceseperation/wiki/Time-Log/_edit\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import torch\n",
    "from torch import hub\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random as random\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "# from .wham_dataset import wham_noise_license\n",
    "\n",
    "# MINI_URL = \"https://zenodo.org/record/3871592/files/MiniLibriMix.zip?download=1\"\n",
    "\n",
    "\n",
    "class CustomOverlay(Dataset):\n",
    "    \"\"\"Dataset class for LibriMix source separation tasks.\n",
    "\n",
    "    Args:\n",
    "        csv_dir (str): The path to the metadata file.\n",
    "        task (str): One of ``'enh_single'``, ``'enh_both'``, ``'sep_clean'`` or\n",
    "            ``'sep_noisy'`` :\n",
    "\n",
    "            * ``'enh_single'`` for single speaker speech enhancement.\n",
    "            * ``'enh_both'`` for multi speaker speech enhancement.\n",
    "            * ``'sep_clean'`` for two-speaker clean source separation.\n",
    "            * ``'sep_noisy'`` for two-speaker noisy source separation.\n",
    "\n",
    "        sample_rate (int) : The sample rate of the sources and mixtures.\n",
    "        n_src (int) : The number of sources in the mixture.\n",
    "        segment (int, optional) : The desired sources and mixtures length in s.\n",
    "\n",
    "    References\n",
    "        [1] \"LibriMix: An Open-Source Dataset for Generalizable Speech Separation\",\n",
    "        Cosentino et al. 2020.\n",
    "    \"\"\"\n",
    "\n",
    "#     dataset_name = \"Random\"\n",
    "\n",
    "    def __init__(\n",
    "        self, csv_dir, dataset_name, sample_rate=22040, \n",
    "    ):\n",
    "        self.csv_dir = csv_dir\n",
    "\n",
    "        # Get the csv corresponding to the dataset (specific character)\n",
    "        md_file = [f for f in os.listdir(csv_dir) if dataset_name in f][0]\n",
    "        self.csv_path = os.path.join(self.csv_dir, md_file)\n",
    "\n",
    "        self.sample_rate = sample_rate\n",
    "        \n",
    "        # Open csv file\n",
    "        self.df = pd.read_csv(self.csv_path)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the row in dataframe\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Get mixture path\n",
    "        mixture_path = row[\"mixture_path\"]\n",
    "        self.mixture_path = mixture_path\n",
    "        sources_list = []\n",
    "        \n",
    "        start = 0\n",
    "        stop = None  \n",
    "\n",
    "        # Read sources\n",
    "        for i in range(self.n_src):\n",
    "            source_path = row[f\"source_{i + 1}_path\"]\n",
    "            s, _ = sf.read(source_path, dtype=\"float32\", start=start, stop=stop)\n",
    "            sources_list.append(s)\n",
    "            \n",
    "        # Read the mixture\n",
    "        mixture, _ = sf.read(mixture_path, dtype=\"float32\", start=start, stop=stop)\n",
    "        # Convert to torch tensor\n",
    "        mixture = torch.from_numpy(mixture)\n",
    "        \n",
    "        # Stack sources (this puts the sources in the same array, but does not combine them)\n",
    "        sources = np.vstack(sources_list)\n",
    "        # Convert sources to tensor\n",
    "        sources = torch.from_numpy(sources)\n",
    "        \n",
    "        return mixture, sources\n",
    "\n",
    "\n",
    "    def get_infos(self):\n",
    "        \"\"\"Get dataset infos (for publishing models).\n",
    "\n",
    "        Returns:\n",
    "            dict, dataset infos with keys `dataset`, `task` and `licences`.\n",
    "        \"\"\"\n",
    "        infos = dict()\n",
    "        infos[\"dataset\"] = self._dataset_name()\n",
    "        infos[\"task\"] = self.task\n",
    "        if self.task == \"sep_clean\":\n",
    "            data_license = [librispeech_license]\n",
    "        else:\n",
    "            data_license = [librispeech_license, wham_noise_license]\n",
    "        infos[\"licenses\"] = data_license\n",
    "        return infos\n",
    "\n",
    "    def _dataset_name(self):\n",
    "        \"\"\" Differentiate between 2 and 3 sources.\"\"\"\n",
    "        return f\"Libri{self.n_src}Mix\"\n",
    "\n",
    "\n",
    "librispeech_license = dict(\n",
    "    title=\"LibriSpeech ASR corpus\",\n",
    "    title_link=\"http://www.openslr.org/12\",\n",
    "    author=\"Vassil Panayotov\",\n",
    "    author_link=\"https://github.com/vdp\",\n",
    "    license=\"CC BY 4.0\",\n",
    "    license_link=\"https://creativecommons.org/licenses/by/4.0/\",\n",
    "    non_commercial=False,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
