{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "856cfbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import cmath\n",
    "import sys\n",
    "import IPython.display as ipd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import make_regression\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d49fd434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_input is of shape (1048, 129, 691)\n",
      "val_input is of shape (225, 129, 691)\n",
      "test_input is of shape (224, 129, 691)\n",
      "train_targets is of shape (1048, 129, 691)\n",
      "val_targets is of shape (225, 129, 691)\n",
      "test_targets is of shape (224, 129, 691)\n",
      "train_noise is of shape (1048, 129, 691)\n",
      "val_noise is of shape (225, 129, 691)\n",
      "test_noise is of shape (224, 129, 691)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Open the training data.\n",
    "\"\"\"\n",
    "training_data_filepath = 'F:/ZaknafeinII_Backup_02-02-22/daea/training_data_generation/id16/output/stft_training_data_dict.pickle'\n",
    "\n",
    "with open(training_data_filepath, 'rb') as f:\n",
    "    data_dict = pickle.load(f)\n",
    "    \n",
    "for key in data_dict:\n",
    "    print(key, 'is of shape', data_dict.get(key).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b52708f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_input.shape: (1048, 129, 691)\n",
      "train_target.shape: (1048, 129, 691)\n",
      "train_input.shape: (1048, 691, 129)\n",
      "train_target.shape: (1048, 691, 129)\n",
      "train_input.shape: (1048, 1, 691, 129)\n",
      "train_target.shape: (1048, 1, 691, 129)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We need to set up the train array, \"Sy\", and the target array, \"R\".\n",
    "\"\"\"\n",
    "train_input = data_dict.get('train_input')\n",
    "stft_clean = data_dict.get('train_targets')\n",
    "stft_noise = data_dict.get('train_noise')\n",
    "\n",
    "# R\n",
    "train_target = []\n",
    "\n",
    "for index in range(0, len(train_input)):\n",
    "    Px = np.square(stft_clean[index])\n",
    "    Pn = np.square(stft_noise[index])\n",
    "    R = Px / sum([Px, Pn])\n",
    "    \n",
    "    train_target.append(R)\n",
    "    \n",
    "train_target = np.array(train_target)\n",
    "\n",
    "print('train_input.shape:', train_input.shape)\n",
    "print('train_target.shape:', train_target.shape)\n",
    "\n",
    "train_input = np.swapaxes(train_input, 1, 2)\n",
    "train_target = np.swapaxes(train_target, 1, 2)\n",
    "\n",
    "print('train_input.shape:', train_input.shape)\n",
    "print('train_target.shape:', train_target.shape)\n",
    "\n",
    "# train_input = train_input.reshape(train_input.shape[0]*train_input.shape[1], train_input.shape[2])\n",
    "# train_target = train_target.reshape(train_target.shape[0]*train_target.shape[1], train_target.shape[2])\n",
    "\n",
    "# print('train_input.shape:', train_input.shape)\n",
    "# print('train_target.shape:', train_target.shape)\n",
    "\n",
    "\n",
    "\n",
    "train_input = train_input.reshape(1048, 1, 691, 129)\n",
    "train_target = train_target.reshape(1048, 1, 691, 129)\n",
    "\n",
    "print('train_input.shape:', train_input.shape)\n",
    "print('train_target.shape:', train_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e057bfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fs = 22050\n",
    "# input_ = train_input[0][:,0:100]\n",
    "# _, xrec = signal.istft(input_, fs)\n",
    "# print('input dim:', input_.shape)\n",
    "# print('output dim:', xrec.shape)\n",
    "# ipd.Audio(xrec, rate=fs)\n",
    "\n",
    "# print()\n",
    "# input_ = train_input[0][:,0]\n",
    "# _, xrec = signal.istft(input_, fs)\n",
    "# print('input dim:', input_.shape)\n",
    "# print('output dim:', xrec.shape)\n",
    "# ipd.Audio(xrec, rate=fs)\n",
    "\n",
    "# counter = 0\n",
    "# for i in train_input[0]:\n",
    "#     if counter < 1:\n",
    "#         print(len(i))\n",
    "#         counter = counter + 1\n",
    "#     else:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52de327f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 1, 691, 129)       16770     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1, 691, 129)       16770     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,540\n",
      "Trainable params: 33,540\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# # do we need the last axis of the Zxx? we should see if it can be reconstructed without it\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, MaxPooling1D, Conv1D, LSTM, Conv2D\n",
    "\n",
    "\n",
    "# NN_model = Sequential()\n",
    "\n",
    "# # The Input Layer :\n",
    "# NN_model.add(Dense(129, kernel_initializer='normal', input_dim = 129, activation='relu'))\n",
    "\n",
    "# # The Hidden Layers :\n",
    "# NN_model.add(Dense(172, kernel_initializer='normal', activation='relu'))\n",
    "# NN_model.add(Dense(129, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "# # The Output Layer :\n",
    "# # changing the output dimensions from 1 to 64\n",
    "# NN_model.add(Dense(129, kernel_initializer='normal', activation='linear'))\n",
    "\n",
    "# # Compile the network :\n",
    "# NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "# NN_model.summary()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# https://stackoverflow.com/questions/61816859/how-to-create-keras-conv2d-layer-on-grayscale-image-set\n",
    "# model.add(Conv1D(filters=258, kernel_size=5, padding='same', activation='relu', input_shape=(None, 129)))\n",
    "model.add(Conv2D(64, (1, 1), activation=\"relu\", input_shape=(1, 691, 129)))\n",
    "model.add(Conv2D(64, (1, 1), activation=\"relu\"))\n",
    "\n",
    "# model.add(MaxPooling1D(pool_size=4))\n",
    "\n",
    "# model.add(LSTM(64))\n",
    "\n",
    "model.add(Dense(129, activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')#, metrics=[metric])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b48698a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Epoch 1/64\n",
      "53/53 [==============================] - 6s 88ms/step - loss: 0.7042 - val_loss: 0.4912\n",
      "Epoch 2/64\n",
      "53/53 [==============================] - 4s 75ms/step - loss: 0.4323 - val_loss: 0.3897\n",
      "Epoch 3/64\n",
      "53/53 [==============================] - 4s 79ms/step - loss: 0.4113 - val_loss: 0.3899\n",
      "Epoch 4/64\n",
      "53/53 [==============================] - 4s 75ms/step - loss: 0.4112 - val_loss: 0.3892\n",
      "Epoch 5/64\n",
      "53/53 [==============================] - 4s 79ms/step - loss: 0.4113 - val_loss: 0.3893\n",
      "Epoch 6/64\n",
      "53/53 [==============================] - 4s 74ms/step - loss: 0.4114 - val_loss: 0.3896\n",
      "Epoch 7/64\n",
      "53/53 [==============================] - 4s 74ms/step - loss: 0.4115 - val_loss: 0.3891\n",
      "Epoch 8/64\n",
      "53/53 [==============================] - 4s 78ms/step - loss: 0.4113 - val_loss: 0.3892\n",
      "Epoch 9/64\n",
      "53/53 [==============================] - 4s 79ms/step - loss: 0.4111 - val_loss: 0.3892\n",
      "Epoch 10/64\n",
      "53/53 [==============================] - 4s 78ms/step - loss: 0.4110 - val_loss: 0.3890\n",
      "Epoch 11/64\n",
      "53/53 [==============================] - 4s 80ms/step - loss: 0.4110 - val_loss: 0.3891\n",
      "Epoch 12/64\n",
      "53/53 [==============================] - 4s 73ms/step - loss: 0.4108 - val_loss: 0.3885\n",
      "Epoch 13/64\n",
      "53/53 [==============================] - 4s 76ms/step - loss: 0.4108 - val_loss: 0.3891\n",
      "Epoch 14/64\n",
      "53/53 [==============================] - 4s 80ms/step - loss: 0.4105 - val_loss: 0.3890\n",
      "Epoch 15/64\n",
      "53/53 [==============================] - 5s 101ms/step - loss: 0.4104 - val_loss: 0.3894\n",
      "Epoch 16/64\n",
      "53/53 [==============================] - 5s 88ms/step - loss: 0.4103 - val_loss: 0.3886\n",
      "Epoch 17/64\n",
      "53/53 [==============================] - 5s 96ms/step - loss: 0.4102 - val_loss: 0.3883\n",
      "Epoch 18/64\n",
      "53/53 [==============================] - 5s 94ms/step - loss: 0.4100 - val_loss: 0.3888\n",
      "Epoch 19/64\n",
      "53/53 [==============================] - 5s 90ms/step - loss: 0.4099 - val_loss: 0.3885\n",
      "Epoch 20/64\n",
      "53/53 [==============================] - 4s 83ms/step - loss: 0.4098 - val_loss: 0.3880\n",
      "Epoch 21/64\n",
      "53/53 [==============================] - 4s 79ms/step - loss: 0.4097 - val_loss: 0.3878\n",
      "Epoch 22/64\n",
      "53/53 [==============================] - 4s 79ms/step - loss: 0.4100 - val_loss: 0.3883\n",
      "Epoch 23/64\n",
      "53/53 [==============================] - 4s 79ms/step - loss: 0.4097 - val_loss: 0.3880\n",
      "Epoch 24/64\n",
      "53/53 [==============================] - 4s 81ms/step - loss: 0.4095 - val_loss: 0.3877\n",
      "Epoch 25/64\n",
      "53/53 [==============================] - 4s 80ms/step - loss: 0.4095 - val_loss: 0.3884\n",
      "Epoch 26/64\n",
      "53/53 [==============================] - 4s 82ms/step - loss: 0.4094 - val_loss: 0.3881\n",
      "Epoch 27/64\n",
      "53/53 [==============================] - 4s 80ms/step - loss: 0.4094 - val_loss: 0.3879\n",
      "Epoch 28/64\n",
      "53/53 [==============================] - 4s 79ms/step - loss: 0.4094 - val_loss: 0.3883\n",
      "Epoch 29/64\n",
      "53/53 [==============================] - 4s 83ms/step - loss: 0.4094 - val_loss: 0.3874\n",
      "Epoch 30/64\n",
      "53/53 [==============================] - 4s 72ms/step - loss: 0.4095 - val_loss: 0.3874\n",
      "Epoch 31/64\n",
      "53/53 [==============================] - 4s 78ms/step - loss: 0.4093 - val_loss: 0.3879\n",
      "Epoch 32/64\n",
      "53/53 [==============================] - 4s 75ms/step - loss: 0.4095 - val_loss: 0.3891\n",
      "Epoch 33/64\n",
      "53/53 [==============================] - 4s 78ms/step - loss: 0.4097 - val_loss: 0.3884\n",
      "Epoch 34/64\n",
      "53/53 [==============================] - 4s 72ms/step - loss: 0.4092 - val_loss: 0.3877\n",
      "Epoch 35/64\n",
      "53/53 [==============================] - 4s 73ms/step - loss: 0.4090 - val_loss: 0.3871\n",
      "Epoch 36/64\n",
      "53/53 [==============================] - 4s 78ms/step - loss: 0.4092 - val_loss: 0.3881\n",
      "Epoch 37/64\n",
      "53/53 [==============================] - 4s 81ms/step - loss: 0.4092 - val_loss: 0.3883\n",
      "Epoch 38/64\n",
      "53/53 [==============================] - 4s 78ms/step - loss: 0.4090 - val_loss: 0.3878\n",
      "Epoch 39/64\n",
      "53/53 [==============================] - 4s 77ms/step - loss: 0.4091 - val_loss: 0.3872\n",
      "Epoch 40/64\n",
      "53/53 [==============================] - 4s 78ms/step - loss: 0.4093 - val_loss: 0.3875\n",
      "Epoch 41/64\n",
      "53/53 [==============================] - 4s 80ms/step - loss: 0.4091 - val_loss: 0.3872\n",
      "Epoch 42/64\n",
      "53/53 [==============================] - 4s 76ms/step - loss: 0.4090 - val_loss: 0.3875\n",
      "Epoch 43/64\n",
      "53/53 [==============================] - 4s 79ms/step - loss: 0.4095 - val_loss: 0.3875\n",
      "Epoch 44/64\n",
      "53/53 [==============================] - 4s 78ms/step - loss: 0.4090 - val_loss: 0.3878\n",
      "Epoch 45/64\n",
      "53/53 [==============================] - 4s 71ms/step - loss: 0.4092 - val_loss: 0.3882\n",
      "Epoch 46/64\n",
      "53/53 [==============================] - 4s 70ms/step - loss: 0.4087 - val_loss: 0.3871\n",
      "Epoch 47/64\n",
      "53/53 [==============================] - 4s 78ms/step - loss: 0.4087 - val_loss: 0.3888\n",
      "Epoch 48/64\n",
      "53/53 [==============================] - 4s 80ms/step - loss: 0.4090 - val_loss: 0.3871\n",
      "Epoch 49/64\n",
      "53/53 [==============================] - 5s 84ms/step - loss: 0.4087 - val_loss: 0.3875\n",
      "Epoch 50/64\n",
      "53/53 [==============================] - 4s 79ms/step - loss: 0.4086 - val_loss: 0.3877\n",
      "Epoch 51/64\n",
      "53/53 [==============================] - 4s 82ms/step - loss: 0.4088 - val_loss: 0.3880\n",
      "Epoch 52/64\n",
      "53/53 [==============================] - 6s 120ms/step - loss: 0.4086 - val_loss: 0.3882\n",
      "Epoch 53/64\n",
      "53/53 [==============================] - 5s 92ms/step - loss: 0.4086 - val_loss: 0.3884\n",
      "Epoch 54/64\n",
      "53/53 [==============================] - 4s 85ms/step - loss: 0.4086 - val_loss: 0.3872\n",
      "Epoch 55/64\n",
      "53/53 [==============================] - 4s 78ms/step - loss: 0.4085 - val_loss: 0.3871\n",
      "Epoch 56/64\n",
      "53/53 [==============================] - 4s 75ms/step - loss: 0.4086 - val_loss: 0.3874\n",
      "Epoch 57/64\n",
      "53/53 [==============================] - 4s 75ms/step - loss: 0.4087 - val_loss: 0.3874\n",
      "Epoch 58/64\n",
      "53/53 [==============================] - 4s 75ms/step - loss: 0.4083 - val_loss: 0.3873\n",
      "Epoch 59/64\n",
      "53/53 [==============================] - 4s 70ms/step - loss: 0.4086 - val_loss: 0.3872\n",
      "Epoch 60/64\n",
      "53/53 [==============================] - 4s 74ms/step - loss: 0.4085 - val_loss: 0.3872\n",
      "Epoch 61/64\n",
      "53/53 [==============================] - 4s 75ms/step - loss: 0.4085 - val_loss: 0.3871\n",
      "Epoch 62/64\n",
      "53/53 [==============================] - 4s 81ms/step - loss: 0.4084 - val_loss: 0.3871\n",
      "Epoch 63/64\n",
      "53/53 [==============================] - 4s 83ms/step - loss: 0.4084 - val_loss: 0.3882\n",
      "Epoch 64/64\n",
      "53/53 [==============================] - 4s 84ms/step - loss: 0.4084 - val_loss: 0.3867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1640ff24b20>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Only save the best form of the model throughout the training process.\n",
    "https://towardsdatascience.com/deep-neural-networks-for-regression-problems-81321897ca33\n",
    "\n",
    "Notes:\n",
    "- look into pruning during training\n",
    "- explore this link: https://towardsdatascience.com/how-to-build-a-neural-network-for-voice-classification-5e2810fe1efa\n",
    "  - has dropout layers\n",
    "  - has graph to show performance over time during training\n",
    "  - has early stopping\n",
    "  - has layers to study\n",
    "- train with GPU somehow\n",
    "- better data preprocessing\n",
    "- From librosa concerning MFCC generation: \"If multi-channel audio input y is provided, the MFCC calculation \n",
    "  will depend on the peak loudness (in decibels) across all channels. The result may differ from independent \n",
    "  MFCC calculation of each channel.\"\n",
    "\"\"\"\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "# adjust values to your needs\n",
    "config = tf.compat.v1.ConfigProto( device_count = {'GPU': 1 , 'CPU': 8} )\n",
    "sess = tf.compat.v1.Session(config=config) \n",
    "K.set_session(sess)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "\n",
    "# checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "# checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "# callbacks_list = [checkpoint]\n",
    "\n",
    "# early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "\n",
    "model.fit(\n",
    "          train_input, \n",
    "          train_target, \n",
    "          epochs=64, \n",
    "          batch_size=16, \n",
    "          validation_split = 0.2, \n",
    "#           callbacks=callbacks_list, \n",
    "          shuffle=True\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20a746ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = data_dict.get('test_input')\n",
    "# test_target = data_dict.get('test_targets')\n",
    "test_input = np.swapaxes(test_input, 1, 2)\n",
    "# test_target = np.swapaxes(test_target, 1, 2)\n",
    "# test_input = test_input.reshape(test_input.shape[0]*test_input.shape[1], test_input.shape[2])\n",
    "# test_target = test_target.reshape(test_target.shape[0]*test_target.shape[1], test_target.shape[2])\n",
    "# print('test_input.shape:', test_input[0].shape)\n",
    "# print('test_target.shape:', test_target.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cdbdd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 691, 129)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\ZaknafeinII\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\ZaknafeinII\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\ZaknafeinII\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\ZaknafeinII\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\ZaknafeinII\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\ZaknafeinII\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 1, 691, 129), found shape=(None, 691, 129)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ZAKNAF~1\\AppData\\Local\\Temp/ipykernel_1244/1133004480.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# y = imask_test[0]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# yhat = NN_model.predict(x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\ZaknafeinII\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\ZaknafeinII\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\ZaknafeinII\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\ZaknafeinII\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\ZaknafeinII\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\ZaknafeinII\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 1, 691, 129), found shape=(None, 691, 129)\n"
     ]
    }
   ],
   "source": [
    "print(test_input[0:2].shape)\n",
    "predictions = np.array(model.predict(test_input[0:2]))\n",
    "print(predictions.shape)\n",
    "# y = imask_test[0]\n",
    "# yhat = NN_model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2935b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e6e703",
   "metadata": {},
   "outputs": [],
   "source": [
    "xhat = predictions[1] * test_input[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a341b59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, xrec = signal.istft(xhat, 22050)\n",
    "print(xrec.shape)\n",
    "ipd.Audio(xrec, rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39212489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
