{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60f3beef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46a6fabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_input is of shape (180518, 64)\n",
      "val_input is of shape (38683, 64)\n",
      "test_input is of shape (38683, 64)\n",
      "train_labels is of shape (180518, 64)\n",
      "val_labels is of shape (38683, 64)\n",
      "test_labels is of shape (38683, 64)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Open the training data.\n",
    "\"\"\"\n",
    "training_data_filepath = 'F:/ZaknafeinII_Backup_02-02-22/daea/training_data_generation/id16/output/mfcc_training_data_dict.pickle'\n",
    "\n",
    "with open(training_data_filepath, 'rb') as f:\n",
    "    data_dict = pickle.load(f)\n",
    "    \n",
    "for key in data_dict:\n",
    "    print(key, 'is of shape', data_dict.get(key).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39225b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Standardize/scale the data.\n",
    "\"\"\"\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "min_max_scaler.fit(np.concatenate((data_dict.get('train_input'),\n",
    "                                   data_dict.get('val_input'),\n",
    "                                   data_dict.get('test_input'),\n",
    "                                   data_dict.get('train_labels'),\n",
    "                                   data_dict.get('val_labels'),\n",
    "                                   data_dict.get('test_labels'))))\n",
    "\n",
    "overlap_train_scaled = min_max_scaler.transform(data_dict.get('train_input'))\n",
    "overlap_val_scaled = min_max_scaler.transform(data_dict.get('val_input'))\n",
    "overlap_test_scaled = min_max_scaler.transform(data_dict.get('test_input'))\n",
    "character_train_scaled = min_max_scaler.transform(data_dict.get('train_labels'))\n",
    "character_val_scaled = min_max_scaler.transform(data_dict.get('val_labels'))\n",
    "character_test_scaled = min_max_scaler.transform(data_dict.get('test_labels'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df814c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZAKNAF~1\\AppData\\Local\\Temp/ipykernel_21308/438024550.py:17: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  imask_train = np.divide(character_train_scaled, overlap_train_scaled)\n",
      "C:\\Users\\ZAKNAF~1\\AppData\\Local\\Temp/ipykernel_21308/438024550.py:18: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  imask_val = np.divide(character_val_scaled, overlap_val_scaled)\n",
      "C:\\Users\\ZAKNAF~1\\AppData\\Local\\Temp/ipykernel_21308/438024550.py:19: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  imask_test = np.divide(character_test_scaled, overlap_test_scaled)\n",
      "C:\\Users\\ZAKNAF~1\\AppData\\Local\\Temp/ipykernel_21308/438024550.py:19: RuntimeWarning: invalid value encountered in true_divide\n",
      "  imask_test = np.divide(character_test_scaled, overlap_test_scaled)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Calculate the ideal masks such that (input vals)*(mask coefficients)=(label vals)\n",
    "So --> (mask coefficients)=(label vals)/(input vals)\n",
    "\"\"\"\n",
    "# zero_count = 0\n",
    "# minimum = -1\n",
    "# for i in overlap_train_scaled:\n",
    "#     for j in i:\n",
    "#         if j == 0:\n",
    "#             zero_count = zero_count + 1\n",
    "#         if minimum == -1 and j != 0:\n",
    "#             minimum = j\n",
    "#         if j < minimum and j != 0:\n",
    "#             minimum = j\n",
    "# print(zero_count, minimum)\n",
    "\n",
    "imask_train = np.divide(character_train_scaled, overlap_train_scaled)\n",
    "imask_val = np.divide(character_val_scaled, overlap_val_scaled)\n",
    "imask_test = np.divide(character_test_scaled, overlap_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f119e5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: (180518, 64)\n",
      "input contains NaN values?: False\n",
      "input contains inf values?: False\n",
      "input datatype: float32\n",
      "output shape: (180518, 64)\n",
      "output contains NaN values?: False\n",
      "output contains inf values?: True\n",
      "output contains inf values?: False\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Given overlap, predict imask.\n",
    "\"\"\"\n",
    "\n",
    "print('input shape:', overlap_train_scaled.shape)\n",
    "print('input contains NaN values?:', np.any(np.isnan(overlap_train_scaled)))\n",
    "print('input contains inf values?:', np.any(np.isinf(overlap_train_scaled)))\n",
    "print('input datatype:', overlap_train_scaled.dtype)\n",
    "overlap_train_scaled = overlap_train_scaled.astype('float32')\n",
    "print('output shape:', imask_train.shape)\n",
    "print('output contains NaN values?:', np.any(np.isnan(imask_train)))\n",
    "print('output contains inf values?:', np.any(np.isinf(imask_train)))\n",
    "imask_train[np.isinf(imask_train)] = 0\n",
    "print('output contains inf values?:', np.any(np.isinf(imask_train)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe4a4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b53eb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# https://machinelearningmastery.com/multi-output-regression-models-with-python/\n",
    "# \"\"\"\n",
    "\n",
    "# model_list = [LinearRegression(), KNeighborsRegressor(), DecisionTreeRegressor()]\n",
    "\n",
    "# for model_type in model_list:\n",
    "#     # define model\n",
    "#     model = model_type\n",
    "#     # fit model\n",
    "#     model.fit(overlap_train_scaled, imask_train)\n",
    "\n",
    "#     x = overlap_test_scaled[0]\n",
    "#     y = imask_test[0]\n",
    "#     yhat = model.predict([x])[0]\n",
    "\n",
    "#     x_axis_list = list(range(0, len(x)))\n",
    "#     plt.plot(x_axis_list, y)\n",
    "#     plt.plot(x_axis_list, yhat)\n",
    "#     plt.title(str(model_type))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76be486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17ec4be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cb9749c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train contains NaN values?: False\n",
      "train contains inf values?: False\n",
      "target shape: (219201, 64)\n",
      "target contains NaN values?: False\n",
      "target contains inf values?: True\n",
      "target contains inf values?: False\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Prepare the training input and target output data\n",
    "Using \"target\" with regression and \"label\" with classification is a a good idea\n",
    "\"\"\"\n",
    "train = np.concatenate((overlap_train_scaled, overlap_val_scaled))\n",
    "target = np.concatenate((imask_train, imask_val))\n",
    "\n",
    "print('train contains NaN values?:', np.any(np.isnan(train)))\n",
    "print('train contains inf values?:', np.any(np.isinf(train)))\n",
    "# print('input datatype:', overlap_train_scaled.dtype)\n",
    "# overlap_train_scaled = overlap_train_scaled.astype('float32')\n",
    "print('target shape:', target.shape)\n",
    "print('target contains NaN values?:', np.any(np.isnan(target)))\n",
    "print('target contains inf values?:', np.any(np.isinf(target)))\n",
    "target[np.isinf(target)] = 0\n",
    "print('target contains inf values?:', np.any(np.isinf(target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef711544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,248\n",
      "Trainable params: 37,248\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Neural network time.\n",
    "Basing work off of the following link:\n",
    "https://towardsdatascience.com/deep-neural-networks-for-regression-problems-81321897ca33\n",
    "https://towardsdatascience.com/how-to-build-a-neural-network-for-voice-classification-5e2810fe1efa\n",
    "\"\"\"\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "\n",
    "\n",
    "NN_model = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "# expecting 64 input dimensions\n",
    "NN_model.add(Dense(64, kernel_initializer='normal', input_dim = 64, activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "# NN_model.add(Dense(256, kernel_initializer='normal', activation='relu'))\n",
    "# NN_model.add(Dense(256, kernel_initializer='normal', activation='relu'))\n",
    "# NN_model.add(Dense(256, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "# just a single 128 is our best looking graph so far\n",
    "# NN_model.add(Dropout(0.1))\n",
    "NN_model.add(Dense(128, activation = 'relu'))\n",
    "# NN_model.add(Dropout(0.15))\n",
    "NN_model.add(Dense(128, activation = 'relu'))\n",
    "# NN_model.add(Dropout(0.25))\n",
    "\n",
    "# The Output Layer :\n",
    "# changing the output dimensions from 1 to 64\n",
    "NN_model.add(Dense(64, kernel_initializer='normal', activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d49d493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0856 - mean_absolute_error: 0.0856 - val_loss: 0.0932 - val_mean_absolute_error: 0.0932\n",
      "Epoch 2/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0855 - mean_absolute_error: 0.0855 - val_loss: 0.0941 - val_mean_absolute_error: 0.0941\n",
      "Epoch 3/512\n",
      "685/685 [==============================] - 2s 2ms/step - loss: 0.0855 - mean_absolute_error: 0.0855 - val_loss: 0.0924 - val_mean_absolute_error: 0.0924\n",
      "Epoch 4/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0855 - mean_absolute_error: 0.0855 - val_loss: 0.0925 - val_mean_absolute_error: 0.0925\n",
      "Epoch 5/512\n",
      "685/685 [==============================] - 2s 2ms/step - loss: 0.0854 - mean_absolute_error: 0.0854 - val_loss: 0.0939 - val_mean_absolute_error: 0.0939\n",
      "Epoch 6/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0854 - mean_absolute_error: 0.0854 - val_loss: 0.0936 - val_mean_absolute_error: 0.0936\n",
      "Epoch 7/512\n",
      "685/685 [==============================] - 2s 2ms/step - loss: 0.0853 - mean_absolute_error: 0.0853 - val_loss: 0.0926 - val_mean_absolute_error: 0.0926\n",
      "Epoch 8/512\n",
      "685/685 [==============================] - 2s 2ms/step - loss: 0.0853 - mean_absolute_error: 0.0853 - val_loss: 0.0928 - val_mean_absolute_error: 0.0928\n",
      "Epoch 9/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0852 - mean_absolute_error: 0.0852 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
      "Epoch 10/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0852 - mean_absolute_error: 0.0852 - val_loss: 0.0928 - val_mean_absolute_error: 0.0928\n",
      "Epoch 11/512\n",
      "685/685 [==============================] - 2s 2ms/step - loss: 0.0852 - mean_absolute_error: 0.0852 - val_loss: 0.0924 - val_mean_absolute_error: 0.0924\n",
      "Epoch 12/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0851 - mean_absolute_error: 0.0851 - val_loss: 0.0924 - val_mean_absolute_error: 0.0924\n",
      "Epoch 13/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0851 - mean_absolute_error: 0.0851 - val_loss: 0.0927 - val_mean_absolute_error: 0.0927\n",
      "Epoch 14/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0851 - mean_absolute_error: 0.0851 - val_loss: 0.0930 - val_mean_absolute_error: 0.0930\n",
      "Epoch 15/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0851 - mean_absolute_error: 0.0851 - val_loss: 0.0924 - val_mean_absolute_error: 0.0924\n",
      "Epoch 16/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0850 - mean_absolute_error: 0.0850 - val_loss: 0.0929 - val_mean_absolute_error: 0.0929\n",
      "Epoch 17/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0850 - mean_absolute_error: 0.0850 - val_loss: 0.0921 - val_mean_absolute_error: 0.0921\n",
      "Epoch 18/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0850 - mean_absolute_error: 0.0850 - val_loss: 0.0923 - val_mean_absolute_error: 0.0923\n",
      "Epoch 19/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0849 - mean_absolute_error: 0.0849 - val_loss: 0.0922 - val_mean_absolute_error: 0.0922\n",
      "Epoch 20/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0849 - mean_absolute_error: 0.0849 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
      "Epoch 21/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0850 - mean_absolute_error: 0.0850 - val_loss: 0.0923 - val_mean_absolute_error: 0.0923\n",
      "Epoch 22/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0849 - mean_absolute_error: 0.0849 - val_loss: 0.0924 - val_mean_absolute_error: 0.0924\n",
      "Epoch 23/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0848 - mean_absolute_error: 0.0848 - val_loss: 0.0932 - val_mean_absolute_error: 0.0932\n",
      "Epoch 24/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0848 - mean_absolute_error: 0.0848 - val_loss: 0.0925 - val_mean_absolute_error: 0.0925\n",
      "Epoch 25/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0848 - mean_absolute_error: 0.0848 - val_loss: 0.0939 - val_mean_absolute_error: 0.0939\n",
      "Epoch 26/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0848 - mean_absolute_error: 0.0848 - val_loss: 0.0935 - val_mean_absolute_error: 0.0935\n",
      "Epoch 27/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0848 - mean_absolute_error: 0.0848 - val_loss: 0.0926 - val_mean_absolute_error: 0.0926\n",
      "Epoch 28/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0847 - mean_absolute_error: 0.0847 - val_loss: 0.0928 - val_mean_absolute_error: 0.0928\n",
      "Epoch 29/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0847 - mean_absolute_error: 0.0847 - val_loss: 0.0926 - val_mean_absolute_error: 0.0926\n",
      "Epoch 30/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0847 - mean_absolute_error: 0.0847 - val_loss: 0.0922 - val_mean_absolute_error: 0.0922\n",
      "Epoch 31/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0846 - mean_absolute_error: 0.0846 - val_loss: 0.0928 - val_mean_absolute_error: 0.0928\n",
      "Epoch 32/512\n",
      "685/685 [==============================] - 2s 2ms/step - loss: 0.0846 - mean_absolute_error: 0.0846 - val_loss: 0.0930 - val_mean_absolute_error: 0.0930\n",
      "Epoch 33/512\n",
      "685/685 [==============================] - 2s 2ms/step - loss: 0.0846 - mean_absolute_error: 0.0846 - val_loss: 0.0930 - val_mean_absolute_error: 0.0930\n",
      "Epoch 34/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0846 - mean_absolute_error: 0.0846 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n",
      "Epoch 35/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0846 - mean_absolute_error: 0.0846 - val_loss: 0.0932 - val_mean_absolute_error: 0.0932\n",
      "Epoch 36/512\n",
      "685/685 [==============================] - 2s 2ms/step - loss: 0.0845 - mean_absolute_error: 0.0845 - val_loss: 0.0928 - val_mean_absolute_error: 0.0928\n",
      "Epoch 37/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0845 - mean_absolute_error: 0.0845 - val_loss: 0.0930 - val_mean_absolute_error: 0.0930\n",
      "Epoch 38/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0845 - mean_absolute_error: 0.0845 - val_loss: 0.0924 - val_mean_absolute_error: 0.0924\n",
      "Epoch 39/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0845 - mean_absolute_error: 0.0845 - val_loss: 0.0930 - val_mean_absolute_error: 0.0930\n",
      "Epoch 40/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0845 - mean_absolute_error: 0.0845 - val_loss: 0.0932 - val_mean_absolute_error: 0.0932\n",
      "Epoch 41/512\n",
      "685/685 [==============================] - 2s 2ms/step - loss: 0.0845 - mean_absolute_error: 0.0845 - val_loss: 0.0931 - val_mean_absolute_error: 0.0931\n",
      "Epoch 42/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0844 - mean_absolute_error: 0.0844 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n",
      "Epoch 43/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0844 - mean_absolute_error: 0.0844 - val_loss: 0.0924 - val_mean_absolute_error: 0.0924\n",
      "Epoch 44/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0844 - mean_absolute_error: 0.0844 - val_loss: 0.0932 - val_mean_absolute_error: 0.0932\n",
      "Epoch 45/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0844 - mean_absolute_error: 0.0844 - val_loss: 0.0929 - val_mean_absolute_error: 0.0929\n",
      "Epoch 46/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0844 - mean_absolute_error: 0.0844 - val_loss: 0.0923 - val_mean_absolute_error: 0.0923\n",
      "Epoch 47/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0843 - mean_absolute_error: 0.0843 - val_loss: 0.0918 - val_mean_absolute_error: 0.0918\n",
      "Epoch 48/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0843 - mean_absolute_error: 0.0843 - val_loss: 0.0925 - val_mean_absolute_error: 0.0925\n",
      "Epoch 49/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0843 - mean_absolute_error: 0.0843 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 50/512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0843 - mean_absolute_error: 0.0843 - val_loss: 0.0935 - val_mean_absolute_error: 0.0935\n",
      "Epoch 51/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0843 - mean_absolute_error: 0.0843 - val_loss: 0.0918 - val_mean_absolute_error: 0.0918\n",
      "Epoch 52/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0842 - mean_absolute_error: 0.0842 - val_loss: 0.0925 - val_mean_absolute_error: 0.0925\n",
      "Epoch 53/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0842 - mean_absolute_error: 0.0842 - val_loss: 0.0927 - val_mean_absolute_error: 0.0927\n",
      "Epoch 54/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0842 - mean_absolute_error: 0.0842 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n",
      "Epoch 55/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0842 - mean_absolute_error: 0.0842 - val_loss: 0.0931 - val_mean_absolute_error: 0.0931\n",
      "Epoch 56/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0842 - mean_absolute_error: 0.0842 - val_loss: 0.0921 - val_mean_absolute_error: 0.0921\n",
      "Epoch 57/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0842 - mean_absolute_error: 0.0842 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
      "Epoch 58/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0842 - mean_absolute_error: 0.0842 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
      "Epoch 59/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0841 - mean_absolute_error: 0.0841 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 60/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0841 - mean_absolute_error: 0.0841 - val_loss: 0.0917 - val_mean_absolute_error: 0.0917\n",
      "Epoch 61/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0841 - mean_absolute_error: 0.0841 - val_loss: 0.0921 - val_mean_absolute_error: 0.0921\n",
      "Epoch 62/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0841 - mean_absolute_error: 0.0841 - val_loss: 0.0918 - val_mean_absolute_error: 0.0918\n",
      "Epoch 63/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0841 - mean_absolute_error: 0.0841 - val_loss: 0.0928 - val_mean_absolute_error: 0.0928\n",
      "Epoch 64/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0841 - mean_absolute_error: 0.0841 - val_loss: 0.0925 - val_mean_absolute_error: 0.0925\n",
      "Epoch 65/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0841 - mean_absolute_error: 0.0841 - val_loss: 0.0923 - val_mean_absolute_error: 0.0923\n",
      "Epoch 66/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0840 - mean_absolute_error: 0.0840 - val_loss: 0.0926 - val_mean_absolute_error: 0.0926\n",
      "Epoch 67/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0841 - mean_absolute_error: 0.0841 - val_loss: 0.0929 - val_mean_absolute_error: 0.0929\n",
      "Epoch 68/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0840 - mean_absolute_error: 0.0840 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
      "Epoch 69/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0840 - mean_absolute_error: 0.0840 - val_loss: 0.0922 - val_mean_absolute_error: 0.0922\n",
      "Epoch 70/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0840 - mean_absolute_error: 0.0840 - val_loss: 0.0927 - val_mean_absolute_error: 0.0927\n",
      "Epoch 71/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0840 - mean_absolute_error: 0.0840 - val_loss: 0.0934 - val_mean_absolute_error: 0.0934\n",
      "Epoch 72/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0840 - mean_absolute_error: 0.0840 - val_loss: 0.0919 - val_mean_absolute_error: 0.0919\n",
      "Epoch 73/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0840 - mean_absolute_error: 0.0840 - val_loss: 0.0921 - val_mean_absolute_error: 0.0921\n",
      "Epoch 74/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0840 - mean_absolute_error: 0.0840 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n",
      "Epoch 75/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0840 - mean_absolute_error: 0.0840 - val_loss: 0.0923 - val_mean_absolute_error: 0.0923\n",
      "Epoch 76/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0839 - mean_absolute_error: 0.0839 - val_loss: 0.0918 - val_mean_absolute_error: 0.0918\n",
      "Epoch 77/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0839 - mean_absolute_error: 0.0839 - val_loss: 0.0925 - val_mean_absolute_error: 0.0925\n",
      "Epoch 78/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0839 - mean_absolute_error: 0.0839 - val_loss: 0.0926 - val_mean_absolute_error: 0.0926\n",
      "Epoch 79/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0840 - mean_absolute_error: 0.0840 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n",
      "Epoch 80/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0839 - mean_absolute_error: 0.0839 - val_loss: 0.0923 - val_mean_absolute_error: 0.0923\n",
      "Epoch 81/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0839 - mean_absolute_error: 0.0839 - val_loss: 0.0919 - val_mean_absolute_error: 0.0919\n",
      "Epoch 82/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0839 - mean_absolute_error: 0.0839 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
      "Epoch 83/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0839 - mean_absolute_error: 0.0839 - val_loss: 0.0932 - val_mean_absolute_error: 0.0932\n",
      "Epoch 84/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0839 - mean_absolute_error: 0.0839 - val_loss: 0.0921 - val_mean_absolute_error: 0.0921\n",
      "Epoch 85/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0839 - mean_absolute_error: 0.0839 - val_loss: 0.0929 - val_mean_absolute_error: 0.0929\n",
      "Epoch 86/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0838 - mean_absolute_error: 0.0838 - val_loss: 0.0932 - val_mean_absolute_error: 0.0932\n",
      "Epoch 87/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0838 - mean_absolute_error: 0.0838 - val_loss: 0.0921 - val_mean_absolute_error: 0.0921\n",
      "Epoch 88/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0838 - mean_absolute_error: 0.0838 - val_loss: 0.0928 - val_mean_absolute_error: 0.0928\n",
      "Epoch 89/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0838 - mean_absolute_error: 0.0838 - val_loss: 0.0921 - val_mean_absolute_error: 0.0921\n",
      "Epoch 90/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0838 - mean_absolute_error: 0.0838 - val_loss: 0.0922 - val_mean_absolute_error: 0.0922\n",
      "Epoch 91/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0838 - mean_absolute_error: 0.0838 - val_loss: 0.0928 - val_mean_absolute_error: 0.0928\n",
      "Epoch 92/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0838 - mean_absolute_error: 0.0838 - val_loss: 0.0939 - val_mean_absolute_error: 0.0939\n",
      "Epoch 93/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0838 - mean_absolute_error: 0.0838 - val_loss: 0.0923 - val_mean_absolute_error: 0.0923\n",
      "Epoch 94/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0837 - mean_absolute_error: 0.0837 - val_loss: 0.0924 - val_mean_absolute_error: 0.0924\n",
      "Epoch 95/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0837 - mean_absolute_error: 0.0837 - val_loss: 0.0924 - val_mean_absolute_error: 0.0924\n",
      "Epoch 96/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0837 - mean_absolute_error: 0.0837 - val_loss: 0.0919 - val_mean_absolute_error: 0.0919\n",
      "Epoch 97/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0837 - mean_absolute_error: 0.0837 - val_loss: 0.0911 - val_mean_absolute_error: 0.0911\n",
      "Epoch 98/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0837 - mean_absolute_error: 0.0837 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
      "Epoch 99/512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0837 - mean_absolute_error: 0.0837 - val_loss: 0.0937 - val_mean_absolute_error: 0.0937\n",
      "Epoch 100/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0837 - mean_absolute_error: 0.0837 - val_loss: 0.0913 - val_mean_absolute_error: 0.0913\n",
      "Epoch 101/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0837 - mean_absolute_error: 0.0837 - val_loss: 0.0922 - val_mean_absolute_error: 0.0922\n",
      "Epoch 102/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0837 - mean_absolute_error: 0.0837 - val_loss: 0.0925 - val_mean_absolute_error: 0.0925\n",
      "Epoch 103/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0836 - mean_absolute_error: 0.0836 - val_loss: 0.0922 - val_mean_absolute_error: 0.0922\n",
      "Epoch 104/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0836 - mean_absolute_error: 0.0836 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
      "Epoch 105/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0836 - mean_absolute_error: 0.0836 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n",
      "Epoch 106/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0836 - mean_absolute_error: 0.0836 - val_loss: 0.0933 - val_mean_absolute_error: 0.0933\n",
      "Epoch 107/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0836 - mean_absolute_error: 0.0836 - val_loss: 0.0925 - val_mean_absolute_error: 0.0925\n",
      "Epoch 108/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0836 - mean_absolute_error: 0.0836 - val_loss: 0.0924 - val_mean_absolute_error: 0.0924\n",
      "Epoch 109/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0836 - mean_absolute_error: 0.0836 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
      "Epoch 110/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0836 - mean_absolute_error: 0.0836 - val_loss: 0.0910 - val_mean_absolute_error: 0.0910\n",
      "Epoch 111/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0836 - mean_absolute_error: 0.0836 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
      "Epoch 112/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0836 - mean_absolute_error: 0.0836 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n",
      "Epoch 113/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0836 - mean_absolute_error: 0.0836 - val_loss: 0.0913 - val_mean_absolute_error: 0.0913\n",
      "Epoch 114/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0836 - mean_absolute_error: 0.0836 - val_loss: 0.0917 - val_mean_absolute_error: 0.0917\n",
      "Epoch 115/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0836 - mean_absolute_error: 0.0836 - val_loss: 0.0931 - val_mean_absolute_error: 0.0931\n",
      "Epoch 116/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0835 - mean_absolute_error: 0.0835 - val_loss: 0.0926 - val_mean_absolute_error: 0.0926\n",
      "Epoch 117/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0835 - mean_absolute_error: 0.0835 - val_loss: 0.0911 - val_mean_absolute_error: 0.0911\n",
      "Epoch 118/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0836 - mean_absolute_error: 0.0836 - val_loss: 0.0927 - val_mean_absolute_error: 0.0927\n",
      "Epoch 119/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0835 - mean_absolute_error: 0.0835 - val_loss: 0.0918 - val_mean_absolute_error: 0.0918\n",
      "Epoch 120/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0835 - mean_absolute_error: 0.0835 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 121/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0835 - mean_absolute_error: 0.0835 - val_loss: 0.0909 - val_mean_absolute_error: 0.0909\n",
      "Epoch 122/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0835 - mean_absolute_error: 0.0835 - val_loss: 0.0921 - val_mean_absolute_error: 0.0921\n",
      "Epoch 123/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0835 - mean_absolute_error: 0.0835 - val_loss: 0.0919 - val_mean_absolute_error: 0.0919\n",
      "Epoch 124/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0835 - mean_absolute_error: 0.0835 - val_loss: 0.0913 - val_mean_absolute_error: 0.0913\n",
      "Epoch 125/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0835 - mean_absolute_error: 0.0835 - val_loss: 0.0911 - val_mean_absolute_error: 0.0911\n",
      "Epoch 126/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0835 - mean_absolute_error: 0.0835 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 127/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0835 - mean_absolute_error: 0.0835 - val_loss: 0.0922 - val_mean_absolute_error: 0.0922\n",
      "Epoch 128/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0834 - mean_absolute_error: 0.0834 - val_loss: 0.0925 - val_mean_absolute_error: 0.0925\n",
      "Epoch 129/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0835 - mean_absolute_error: 0.0835 - val_loss: 0.0918 - val_mean_absolute_error: 0.0918\n",
      "Epoch 130/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0835 - mean_absolute_error: 0.0835 - val_loss: 0.0921 - val_mean_absolute_error: 0.0921\n",
      "Epoch 131/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0834 - mean_absolute_error: 0.0834 - val_loss: 0.0925 - val_mean_absolute_error: 0.0925\n",
      "Epoch 132/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0834 - mean_absolute_error: 0.0834 - val_loss: 0.0921 - val_mean_absolute_error: 0.0921\n",
      "Epoch 133/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0834 - mean_absolute_error: 0.0834 - val_loss: 0.0917 - val_mean_absolute_error: 0.0917\n",
      "Epoch 134/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0834 - mean_absolute_error: 0.0834 - val_loss: 0.0926 - val_mean_absolute_error: 0.0926\n",
      "Epoch 135/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0834 - mean_absolute_error: 0.0834 - val_loss: 0.0918 - val_mean_absolute_error: 0.0918\n",
      "Epoch 136/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0834 - mean_absolute_error: 0.0834 - val_loss: 0.0923 - val_mean_absolute_error: 0.0923\n",
      "Epoch 137/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0834 - mean_absolute_error: 0.0834 - val_loss: 0.0918 - val_mean_absolute_error: 0.0918\n",
      "Epoch 138/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0834 - mean_absolute_error: 0.0834 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
      "Epoch 139/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0834 - mean_absolute_error: 0.0834 - val_loss: 0.0914 - val_mean_absolute_error: 0.0914\n",
      "Epoch 140/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0834 - mean_absolute_error: 0.0834 - val_loss: 0.0914 - val_mean_absolute_error: 0.0914\n",
      "Epoch 141/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0833 - mean_absolute_error: 0.0833 - val_loss: 0.0927 - val_mean_absolute_error: 0.0927\n",
      "Epoch 142/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0834 - mean_absolute_error: 0.0834 - val_loss: 0.0921 - val_mean_absolute_error: 0.0921\n",
      "Epoch 143/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0834 - mean_absolute_error: 0.0834 - val_loss: 0.0925 - val_mean_absolute_error: 0.0925\n",
      "Epoch 144/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0833 - mean_absolute_error: 0.0833 - val_loss: 0.0917 - val_mean_absolute_error: 0.0917\n",
      "Epoch 145/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0834 - mean_absolute_error: 0.0834 - val_loss: 0.0917 - val_mean_absolute_error: 0.0917\n",
      "Epoch 146/512\n",
      "685/685 [==============================] - 2s 2ms/step - loss: 0.0833 - mean_absolute_error: 0.0833 - val_loss: 0.0925 - val_mean_absolute_error: 0.0925\n",
      "Epoch 147/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0834 - mean_absolute_error: 0.0834 - val_loss: 0.0918 - val_mean_absolute_error: 0.0918\n",
      "Epoch 148/512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0834 - mean_absolute_error: 0.0834 - val_loss: 0.0924 - val_mean_absolute_error: 0.0924\n",
      "Epoch 149/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0833 - mean_absolute_error: 0.0833 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 150/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0833 - mean_absolute_error: 0.0833 - val_loss: 0.0926 - val_mean_absolute_error: 0.0926\n",
      "Epoch 151/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0833 - mean_absolute_error: 0.0833 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
      "Epoch 152/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0833 - mean_absolute_error: 0.0833 - val_loss: 0.0912 - val_mean_absolute_error: 0.0912\n",
      "Epoch 153/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0833 - mean_absolute_error: 0.0833 - val_loss: 0.0912 - val_mean_absolute_error: 0.0912\n",
      "Epoch 154/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0833 - mean_absolute_error: 0.0833 - val_loss: 0.0930 - val_mean_absolute_error: 0.0930\n",
      "Epoch 155/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0833 - mean_absolute_error: 0.0833 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n",
      "Epoch 156/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0833 - mean_absolute_error: 0.0833 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
      "Epoch 157/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0833 - mean_absolute_error: 0.0833 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
      "Epoch 158/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0833 - mean_absolute_error: 0.0833 - val_loss: 0.0921 - val_mean_absolute_error: 0.0921\n",
      "Epoch 159/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0833 - mean_absolute_error: 0.0833 - val_loss: 0.0914 - val_mean_absolute_error: 0.0914\n",
      "Epoch 160/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0833 - mean_absolute_error: 0.0833 - val_loss: 0.0912 - val_mean_absolute_error: 0.0912\n",
      "Epoch 161/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0832 - mean_absolute_error: 0.0832 - val_loss: 0.0912 - val_mean_absolute_error: 0.0912\n",
      "Epoch 162/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0832 - mean_absolute_error: 0.0832 - val_loss: 0.0913 - val_mean_absolute_error: 0.0913\n",
      "Epoch 163/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0832 - mean_absolute_error: 0.0832 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 164/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0832 - mean_absolute_error: 0.0832 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n",
      "Epoch 165/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0832 - mean_absolute_error: 0.0832 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 166/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0832 - mean_absolute_error: 0.0832 - val_loss: 0.0924 - val_mean_absolute_error: 0.0924\n",
      "Epoch 167/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0832 - mean_absolute_error: 0.0832 - val_loss: 0.0924 - val_mean_absolute_error: 0.0924\n",
      "Epoch 168/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0832 - mean_absolute_error: 0.0832 - val_loss: 0.0924 - val_mean_absolute_error: 0.0924\n",
      "Epoch 169/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0832 - mean_absolute_error: 0.0832 - val_loss: 0.0918 - val_mean_absolute_error: 0.0918\n",
      "Epoch 170/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0832 - mean_absolute_error: 0.0832 - val_loss: 0.0913 - val_mean_absolute_error: 0.0913\n",
      "Epoch 171/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0832 - mean_absolute_error: 0.0832 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
      "Epoch 172/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0832 - mean_absolute_error: 0.0832 - val_loss: 0.0917 - val_mean_absolute_error: 0.0917\n",
      "Epoch 173/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0832 - mean_absolute_error: 0.0832 - val_loss: 0.0918 - val_mean_absolute_error: 0.0918\n",
      "Epoch 174/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0832 - mean_absolute_error: 0.0832 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
      "Epoch 175/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0831 - mean_absolute_error: 0.0831 - val_loss: 0.0929 - val_mean_absolute_error: 0.0929\n",
      "Epoch 176/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0832 - mean_absolute_error: 0.0832 - val_loss: 0.0911 - val_mean_absolute_error: 0.0911\n",
      "Epoch 177/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0831 - mean_absolute_error: 0.0831 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
      "Epoch 178/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0832 - mean_absolute_error: 0.0832 - val_loss: 0.0925 - val_mean_absolute_error: 0.0925\n",
      "Epoch 179/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0831 - mean_absolute_error: 0.0831 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 180/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0831 - mean_absolute_error: 0.0831 - val_loss: 0.0929 - val_mean_absolute_error: 0.0929\n",
      "Epoch 181/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0831 - mean_absolute_error: 0.0831 - val_loss: 0.0918 - val_mean_absolute_error: 0.0918\n",
      "Epoch 182/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0831 - mean_absolute_error: 0.0831 - val_loss: 0.0919 - val_mean_absolute_error: 0.0919\n",
      "Epoch 183/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0831 - mean_absolute_error: 0.0831 - val_loss: 0.0914 - val_mean_absolute_error: 0.0914\n",
      "Epoch 184/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0831 - mean_absolute_error: 0.0831 - val_loss: 0.0914 - val_mean_absolute_error: 0.0914\n",
      "Epoch 185/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0831 - mean_absolute_error: 0.0831 - val_loss: 0.0918 - val_mean_absolute_error: 0.0918\n",
      "Epoch 186/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0831 - mean_absolute_error: 0.0831 - val_loss: 0.0919 - val_mean_absolute_error: 0.0919\n",
      "Epoch 187/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0831 - mean_absolute_error: 0.0831 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 188/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0831 - mean_absolute_error: 0.0831 - val_loss: 0.0917 - val_mean_absolute_error: 0.0917\n",
      "Epoch 189/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0831 - mean_absolute_error: 0.0831 - val_loss: 0.0935 - val_mean_absolute_error: 0.0935\n",
      "Epoch 190/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0831 - mean_absolute_error: 0.0831 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n",
      "Epoch 191/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0831 - mean_absolute_error: 0.0831 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
      "Epoch 192/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0831 - mean_absolute_error: 0.0831 - val_loss: 0.0913 - val_mean_absolute_error: 0.0913\n",
      "Epoch 193/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0831 - mean_absolute_error: 0.0831 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 194/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0830 - mean_absolute_error: 0.0830 - val_loss: 0.0917 - val_mean_absolute_error: 0.0917\n",
      "Epoch 195/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0831 - mean_absolute_error: 0.0831 - val_loss: 0.0926 - val_mean_absolute_error: 0.0926\n",
      "Epoch 196/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0830 - mean_absolute_error: 0.0830 - val_loss: 0.0926 - val_mean_absolute_error: 0.0926\n",
      "Epoch 197/512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0831 - mean_absolute_error: 0.0831 - val_loss: 0.0922 - val_mean_absolute_error: 0.0922\n",
      "Epoch 198/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0830 - mean_absolute_error: 0.0830 - val_loss: 0.0922 - val_mean_absolute_error: 0.0922\n",
      "Epoch 199/512\n",
      "685/685 [==============================] - 2s 2ms/step - loss: 0.0830 - mean_absolute_error: 0.0830 - val_loss: 0.0918 - val_mean_absolute_error: 0.0918\n",
      "Epoch 200/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0830 - mean_absolute_error: 0.0830 - val_loss: 0.0917 - val_mean_absolute_error: 0.0917\n",
      "Epoch 201/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0830 - mean_absolute_error: 0.0830 - val_loss: 0.0912 - val_mean_absolute_error: 0.0912\n",
      "Epoch 202/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0830 - mean_absolute_error: 0.0830 - val_loss: 0.0925 - val_mean_absolute_error: 0.0925\n",
      "Epoch 203/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0830 - mean_absolute_error: 0.0830 - val_loss: 0.0921 - val_mean_absolute_error: 0.0921\n",
      "Epoch 204/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0830 - mean_absolute_error: 0.0830 - val_loss: 0.0925 - val_mean_absolute_error: 0.0925\n",
      "Epoch 205/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0829 - mean_absolute_error: 0.0829 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
      "Epoch 206/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0830 - mean_absolute_error: 0.0830 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 207/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0830 - mean_absolute_error: 0.0830 - val_loss: 0.0919 - val_mean_absolute_error: 0.0919\n",
      "Epoch 208/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0830 - mean_absolute_error: 0.0830 - val_loss: 0.0917 - val_mean_absolute_error: 0.0917\n",
      "Epoch 209/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0830 - mean_absolute_error: 0.0830 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
      "Epoch 210/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0830 - mean_absolute_error: 0.0830 - val_loss: 0.0913 - val_mean_absolute_error: 0.0913\n",
      "Epoch 211/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0830 - mean_absolute_error: 0.0830 - val_loss: 0.0911 - val_mean_absolute_error: 0.0911\n",
      "Epoch 212/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0830 - mean_absolute_error: 0.0830 - val_loss: 0.0925 - val_mean_absolute_error: 0.0925\n",
      "Epoch 213/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0830 - mean_absolute_error: 0.0830 - val_loss: 0.0924 - val_mean_absolute_error: 0.0924\n",
      "Epoch 214/512\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.0830 - mean_absolute_error: 0.0830 - val_loss: 0.0925 - val_mean_absolute_error: 0.0925\n",
      "Epoch 215/512\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.0830 - mean_absolute_error: 0.0830 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 216/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0829 - mean_absolute_error: 0.0829 - val_loss: 0.0912 - val_mean_absolute_error: 0.0912\n",
      "Epoch 217/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0830 - mean_absolute_error: 0.0830 - val_loss: 0.0919 - val_mean_absolute_error: 0.0919\n",
      "Epoch 218/512\n",
      "685/685 [==============================] - 2s 4ms/step - loss: 0.0829 - mean_absolute_error: 0.0829 - val_loss: 0.0919 - val_mean_absolute_error: 0.0919\n",
      "Epoch 219/512\n",
      "685/685 [==============================] - 2s 4ms/step - loss: 0.0829 - mean_absolute_error: 0.0829 - val_loss: 0.0924 - val_mean_absolute_error: 0.0924\n",
      "Epoch 220/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0829 - mean_absolute_error: 0.0829 - val_loss: 0.0923 - val_mean_absolute_error: 0.0923\n",
      "Epoch 221/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0829 - mean_absolute_error: 0.0829 - val_loss: 0.0913 - val_mean_absolute_error: 0.0913\n",
      "Epoch 222/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0830 - mean_absolute_error: 0.0830 - val_loss: 0.0913 - val_mean_absolute_error: 0.0913\n",
      "Epoch 223/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0829 - mean_absolute_error: 0.0829 - val_loss: 0.0917 - val_mean_absolute_error: 0.0917\n",
      "Epoch 224/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0829 - mean_absolute_error: 0.0829 - val_loss: 0.0924 - val_mean_absolute_error: 0.0924\n",
      "Epoch 225/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0829 - mean_absolute_error: 0.0829 - val_loss: 0.0925 - val_mean_absolute_error: 0.0925\n",
      "Epoch 226/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0829 - mean_absolute_error: 0.0829 - val_loss: 0.0921 - val_mean_absolute_error: 0.0921\n",
      "Epoch 227/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0829 - mean_absolute_error: 0.0829 - val_loss: 0.0914 - val_mean_absolute_error: 0.0914\n",
      "Epoch 228/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0829 - mean_absolute_error: 0.0829 - val_loss: 0.0911 - val_mean_absolute_error: 0.0911\n",
      "Epoch 229/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0829 - mean_absolute_error: 0.0829 - val_loss: 0.0917 - val_mean_absolute_error: 0.0917\n",
      "Epoch 230/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0829 - mean_absolute_error: 0.0829 - val_loss: 0.0917 - val_mean_absolute_error: 0.0917\n",
      "Epoch 231/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0829 - mean_absolute_error: 0.0829 - val_loss: 0.0910 - val_mean_absolute_error: 0.0910\n",
      "Epoch 232/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0829 - mean_absolute_error: 0.0829 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 233/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0829 - mean_absolute_error: 0.0829 - val_loss: 0.0923 - val_mean_absolute_error: 0.0923\n",
      "Epoch 234/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0829 - mean_absolute_error: 0.0829 - val_loss: 0.0921 - val_mean_absolute_error: 0.0921\n",
      "Epoch 235/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0829 - mean_absolute_error: 0.0829 - val_loss: 0.0911 - val_mean_absolute_error: 0.0911\n",
      "Epoch 236/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0829 - mean_absolute_error: 0.0829 - val_loss: 0.0919 - val_mean_absolute_error: 0.0919\n",
      "Epoch 237/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0829 - mean_absolute_error: 0.0829 - val_loss: 0.0923 - val_mean_absolute_error: 0.0923\n",
      "Epoch 238/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0829 - mean_absolute_error: 0.0829 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
      "Epoch 239/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0829 - mean_absolute_error: 0.0829 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
      "Epoch 240/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0829 - mean_absolute_error: 0.0829 - val_loss: 0.0925 - val_mean_absolute_error: 0.0925\n",
      "Epoch 241/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0828 - mean_absolute_error: 0.0828 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n",
      "Epoch 242/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0829 - mean_absolute_error: 0.0829 - val_loss: 0.0926 - val_mean_absolute_error: 0.0926\n",
      "Epoch 243/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0829 - mean_absolute_error: 0.0829 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
      "Epoch 244/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0829 - mean_absolute_error: 0.0829 - val_loss: 0.0927 - val_mean_absolute_error: 0.0927\n",
      "Epoch 245/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0828 - mean_absolute_error: 0.0828 - val_loss: 0.0911 - val_mean_absolute_error: 0.0911\n",
      "Epoch 246/512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0828 - mean_absolute_error: 0.0828 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n",
      "Epoch 247/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0828 - mean_absolute_error: 0.0828 - val_loss: 0.0919 - val_mean_absolute_error: 0.0919\n",
      "Epoch 248/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0828 - mean_absolute_error: 0.0828 - val_loss: 0.0922 - val_mean_absolute_error: 0.0922\n",
      "Epoch 249/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0828 - mean_absolute_error: 0.0828 - val_loss: 0.0921 - val_mean_absolute_error: 0.0921\n",
      "Epoch 250/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0828 - mean_absolute_error: 0.0828 - val_loss: 0.0918 - val_mean_absolute_error: 0.0918\n",
      "Epoch 251/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0828 - mean_absolute_error: 0.0828 - val_loss: 0.0914 - val_mean_absolute_error: 0.0914\n",
      "Epoch 252/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0828 - mean_absolute_error: 0.0828 - val_loss: 0.0909 - val_mean_absolute_error: 0.0909\n",
      "Epoch 253/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0828 - mean_absolute_error: 0.0828 - val_loss: 0.0922 - val_mean_absolute_error: 0.0922\n",
      "Epoch 254/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0828 - mean_absolute_error: 0.0828 - val_loss: 0.0918 - val_mean_absolute_error: 0.0918\n",
      "Epoch 255/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0828 - mean_absolute_error: 0.0828 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 256/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0828 - mean_absolute_error: 0.0828 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
      "Epoch 257/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0828 - mean_absolute_error: 0.0828 - val_loss: 0.0921 - val_mean_absolute_error: 0.0921\n",
      "Epoch 258/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0828 - mean_absolute_error: 0.0828 - val_loss: 0.0927 - val_mean_absolute_error: 0.0927\n",
      "Epoch 259/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0828 - mean_absolute_error: 0.0828 - val_loss: 0.0912 - val_mean_absolute_error: 0.0912\n",
      "Epoch 260/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0828 - mean_absolute_error: 0.0828 - val_loss: 0.0929 - val_mean_absolute_error: 0.0929\n",
      "Epoch 261/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0828 - mean_absolute_error: 0.0828 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
      "Epoch 262/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0828 - mean_absolute_error: 0.0828 - val_loss: 0.0923 - val_mean_absolute_error: 0.0923\n",
      "Epoch 263/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0828 - mean_absolute_error: 0.0828 - val_loss: 0.0928 - val_mean_absolute_error: 0.0928\n",
      "Epoch 264/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0828 - mean_absolute_error: 0.0828 - val_loss: 0.0922 - val_mean_absolute_error: 0.0922\n",
      "Epoch 265/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0828 - mean_absolute_error: 0.0828 - val_loss: 0.0918 - val_mean_absolute_error: 0.0918\n",
      "Epoch 266/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0828 - mean_absolute_error: 0.0828 - val_loss: 0.0912 - val_mean_absolute_error: 0.0912\n",
      "Epoch 267/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0827 - mean_absolute_error: 0.0827 - val_loss: 0.0921 - val_mean_absolute_error: 0.0921\n",
      "Epoch 268/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0828 - mean_absolute_error: 0.0828 - val_loss: 0.0910 - val_mean_absolute_error: 0.0910\n",
      "Epoch 269/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0828 - mean_absolute_error: 0.0828 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n",
      "Epoch 270/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0827 - mean_absolute_error: 0.0827 - val_loss: 0.0914 - val_mean_absolute_error: 0.0914\n",
      "Epoch 271/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0827 - mean_absolute_error: 0.0827 - val_loss: 0.0914 - val_mean_absolute_error: 0.0914\n",
      "Epoch 272/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0827 - mean_absolute_error: 0.0827 - val_loss: 0.0926 - val_mean_absolute_error: 0.0926\n",
      "Epoch 273/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0827 - mean_absolute_error: 0.0827 - val_loss: 0.0923 - val_mean_absolute_error: 0.0923\n",
      "Epoch 274/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0827 - mean_absolute_error: 0.0827 - val_loss: 0.0921 - val_mean_absolute_error: 0.0921\n",
      "Epoch 275/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0827 - mean_absolute_error: 0.0827 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 276/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0827 - mean_absolute_error: 0.0827 - val_loss: 0.0914 - val_mean_absolute_error: 0.0914\n",
      "Epoch 277/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0827 - mean_absolute_error: 0.0827 - val_loss: 0.0918 - val_mean_absolute_error: 0.0918\n",
      "Epoch 278/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0827 - mean_absolute_error: 0.0827 - val_loss: 0.0912 - val_mean_absolute_error: 0.0912\n",
      "Epoch 279/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0827 - mean_absolute_error: 0.0827 - val_loss: 0.0909 - val_mean_absolute_error: 0.0909\n",
      "Epoch 280/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0827 - mean_absolute_error: 0.0827 - val_loss: 0.0919 - val_mean_absolute_error: 0.0919\n",
      "Epoch 281/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0827 - mean_absolute_error: 0.0827 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n",
      "Epoch 282/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0827 - mean_absolute_error: 0.0827 - val_loss: 0.0913 - val_mean_absolute_error: 0.0913\n",
      "Epoch 283/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0827 - mean_absolute_error: 0.0827 - val_loss: 0.0919 - val_mean_absolute_error: 0.0919\n",
      "Epoch 284/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0827 - mean_absolute_error: 0.0827 - val_loss: 0.0907 - val_mean_absolute_error: 0.0907\n",
      "Epoch 285/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0827 - mean_absolute_error: 0.0827 - val_loss: 0.0911 - val_mean_absolute_error: 0.0911\n",
      "Epoch 286/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0827 - mean_absolute_error: 0.0827 - val_loss: 0.0908 - val_mean_absolute_error: 0.0908\n",
      "Epoch 287/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0827 - mean_absolute_error: 0.0827 - val_loss: 0.0913 - val_mean_absolute_error: 0.0913\n",
      "Epoch 288/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0827 - mean_absolute_error: 0.0827 - val_loss: 0.0913 - val_mean_absolute_error: 0.0913\n",
      "Epoch 289/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0827 - mean_absolute_error: 0.0827 - val_loss: 0.0914 - val_mean_absolute_error: 0.0914\n",
      "Epoch 290/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0827 - mean_absolute_error: 0.0827 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 291/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0827 - mean_absolute_error: 0.0827 - val_loss: 0.0912 - val_mean_absolute_error: 0.0912\n",
      "Epoch 292/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0826 - mean_absolute_error: 0.0826 - val_loss: 0.0910 - val_mean_absolute_error: 0.0910\n",
      "Epoch 293/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0827 - mean_absolute_error: 0.0827 - val_loss: 0.0922 - val_mean_absolute_error: 0.0922\n",
      "Epoch 294/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0826 - mean_absolute_error: 0.0826 - val_loss: 0.0908 - val_mean_absolute_error: 0.0908\n",
      "Epoch 295/512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0826 - mean_absolute_error: 0.0826 - val_loss: 0.0911 - val_mean_absolute_error: 0.0911\n",
      "Epoch 296/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0826 - mean_absolute_error: 0.0826 - val_loss: 0.0925 - val_mean_absolute_error: 0.0925\n",
      "Epoch 297/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0826 - mean_absolute_error: 0.0826 - val_loss: 0.0928 - val_mean_absolute_error: 0.0928\n",
      "Epoch 298/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0826 - mean_absolute_error: 0.0826 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n",
      "Epoch 299/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0826 - mean_absolute_error: 0.0826 - val_loss: 0.0928 - val_mean_absolute_error: 0.0928\n",
      "Epoch 300/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0826 - mean_absolute_error: 0.0826 - val_loss: 0.0921 - val_mean_absolute_error: 0.0921\n",
      "Epoch 301/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0826 - mean_absolute_error: 0.0826 - val_loss: 0.0914 - val_mean_absolute_error: 0.0914\n",
      "Epoch 302/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0826 - mean_absolute_error: 0.0826 - val_loss: 0.0913 - val_mean_absolute_error: 0.0913\n",
      "Epoch 303/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0826 - mean_absolute_error: 0.0826 - val_loss: 0.0919 - val_mean_absolute_error: 0.0919\n",
      "Epoch 304/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0826 - mean_absolute_error: 0.0826 - val_loss: 0.0919 - val_mean_absolute_error: 0.0919\n",
      "Epoch 305/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0826 - mean_absolute_error: 0.0826 - val_loss: 0.0914 - val_mean_absolute_error: 0.0914\n",
      "Epoch 306/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0826 - mean_absolute_error: 0.0826 - val_loss: 0.0918 - val_mean_absolute_error: 0.0918\n",
      "Epoch 307/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0826 - mean_absolute_error: 0.0826 - val_loss: 0.0912 - val_mean_absolute_error: 0.0912\n",
      "Epoch 308/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0826 - mean_absolute_error: 0.0826 - val_loss: 0.0919 - val_mean_absolute_error: 0.0919\n",
      "Epoch 309/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0825 - mean_absolute_error: 0.0825 - val_loss: 0.0923 - val_mean_absolute_error: 0.0923\n",
      "Epoch 310/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0826 - mean_absolute_error: 0.0826 - val_loss: 0.0912 - val_mean_absolute_error: 0.0912\n",
      "Epoch 311/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0826 - mean_absolute_error: 0.0826 - val_loss: 0.0914 - val_mean_absolute_error: 0.0914\n",
      "Epoch 312/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0826 - mean_absolute_error: 0.0826 - val_loss: 0.0913 - val_mean_absolute_error: 0.0913\n",
      "Epoch 313/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0825 - mean_absolute_error: 0.0825 - val_loss: 0.0918 - val_mean_absolute_error: 0.0918\n",
      "Epoch 314/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0826 - mean_absolute_error: 0.0826 - val_loss: 0.0912 - val_mean_absolute_error: 0.0912\n",
      "Epoch 315/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0825 - mean_absolute_error: 0.0825 - val_loss: 0.0919 - val_mean_absolute_error: 0.0919\n",
      "Epoch 316/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0826 - mean_absolute_error: 0.0826 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
      "Epoch 317/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0825 - mean_absolute_error: 0.0825 - val_loss: 0.0911 - val_mean_absolute_error: 0.0911\n",
      "Epoch 318/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0825 - mean_absolute_error: 0.0825 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
      "Epoch 319/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0825 - mean_absolute_error: 0.0825 - val_loss: 0.0918 - val_mean_absolute_error: 0.0918\n",
      "Epoch 320/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0825 - mean_absolute_error: 0.0825 - val_loss: 0.0914 - val_mean_absolute_error: 0.0914\n",
      "Epoch 321/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0825 - mean_absolute_error: 0.0825 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n",
      "Epoch 322/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0825 - mean_absolute_error: 0.0825 - val_loss: 0.0910 - val_mean_absolute_error: 0.0910\n",
      "Epoch 323/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0825 - mean_absolute_error: 0.0825 - val_loss: 0.0908 - val_mean_absolute_error: 0.0908\n",
      "Epoch 324/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0825 - mean_absolute_error: 0.0825 - val_loss: 0.0919 - val_mean_absolute_error: 0.0919\n",
      "Epoch 325/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0825 - mean_absolute_error: 0.0825 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 326/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0825 - mean_absolute_error: 0.0825 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n",
      "Epoch 327/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0825 - mean_absolute_error: 0.0825 - val_loss: 0.0917 - val_mean_absolute_error: 0.0917\n",
      "Epoch 328/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0825 - mean_absolute_error: 0.0825 - val_loss: 0.0921 - val_mean_absolute_error: 0.0921\n",
      "Epoch 329/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0825 - mean_absolute_error: 0.0825 - val_loss: 0.0914 - val_mean_absolute_error: 0.0914\n",
      "Epoch 330/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0825 - mean_absolute_error: 0.0825 - val_loss: 0.0910 - val_mean_absolute_error: 0.0910\n",
      "Epoch 331/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0825 - mean_absolute_error: 0.0825 - val_loss: 0.0922 - val_mean_absolute_error: 0.0922\n",
      "Epoch 332/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0825 - mean_absolute_error: 0.0825 - val_loss: 0.0910 - val_mean_absolute_error: 0.0910\n",
      "Epoch 333/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0825 - mean_absolute_error: 0.0825 - val_loss: 0.0914 - val_mean_absolute_error: 0.0914\n",
      "Epoch 334/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0825 - mean_absolute_error: 0.0825 - val_loss: 0.0908 - val_mean_absolute_error: 0.0908\n",
      "Epoch 335/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.0824 - val_loss: 0.0909 - val_mean_absolute_error: 0.0909\n",
      "Epoch 336/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0825 - mean_absolute_error: 0.0825 - val_loss: 0.0918 - val_mean_absolute_error: 0.0918\n",
      "Epoch 337/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0825 - mean_absolute_error: 0.0825 - val_loss: 0.0913 - val_mean_absolute_error: 0.0913\n",
      "Epoch 338/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.0824 - val_loss: 0.0910 - val_mean_absolute_error: 0.0910\n",
      "Epoch 339/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0825 - mean_absolute_error: 0.0825 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n",
      "Epoch 340/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.0824 - val_loss: 0.0911 - val_mean_absolute_error: 0.0911\n",
      "Epoch 341/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.0824 - val_loss: 0.0907 - val_mean_absolute_error: 0.0907\n",
      "Epoch 342/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.0824 - val_loss: 0.0909 - val_mean_absolute_error: 0.0909\n",
      "Epoch 343/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.0824 - val_loss: 0.0927 - val_mean_absolute_error: 0.0927\n",
      "Epoch 344/512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0825 - mean_absolute_error: 0.0825 - val_loss: 0.0922 - val_mean_absolute_error: 0.0922\n",
      "Epoch 345/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.0824 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 346/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.0824 - val_loss: 0.0926 - val_mean_absolute_error: 0.0926\n",
      "Epoch 347/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.0824 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 348/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.0824 - val_loss: 0.0917 - val_mean_absolute_error: 0.0917\n",
      "Epoch 349/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.0824 - val_loss: 0.0909 - val_mean_absolute_error: 0.0909\n",
      "Epoch 350/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.0824 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 351/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.0824 - val_loss: 0.0921 - val_mean_absolute_error: 0.0921\n",
      "Epoch 352/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.0824 - val_loss: 0.0913 - val_mean_absolute_error: 0.0913\n",
      "Epoch 353/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.0824 - val_loss: 0.0917 - val_mean_absolute_error: 0.0917\n",
      "Epoch 354/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.0824 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n",
      "Epoch 355/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.0824 - val_loss: 0.0927 - val_mean_absolute_error: 0.0927\n",
      "Epoch 356/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.0824 - val_loss: 0.0908 - val_mean_absolute_error: 0.0908\n",
      "Epoch 357/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.0824 - val_loss: 0.0911 - val_mean_absolute_error: 0.0911\n",
      "Epoch 358/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.0824 - val_loss: 0.0907 - val_mean_absolute_error: 0.0907\n",
      "Epoch 359/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.0824 - val_loss: 0.0936 - val_mean_absolute_error: 0.0936\n",
      "Epoch 360/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.0824 - val_loss: 0.0917 - val_mean_absolute_error: 0.0917\n",
      "Epoch 361/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.0824 - val_loss: 0.0911 - val_mean_absolute_error: 0.0911\n",
      "Epoch 362/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0909 - val_mean_absolute_error: 0.0909\n",
      "Epoch 363/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0910 - val_mean_absolute_error: 0.0910\n",
      "Epoch 364/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.0824 - val_loss: 0.0905 - val_mean_absolute_error: 0.0905\n",
      "Epoch 365/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
      "Epoch 366/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.0824 - val_loss: 0.0914 - val_mean_absolute_error: 0.0914\n",
      "Epoch 367/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0923 - val_mean_absolute_error: 0.0923\n",
      "Epoch 368/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.0824 - val_loss: 0.0913 - val_mean_absolute_error: 0.0913\n",
      "Epoch 369/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0919 - val_mean_absolute_error: 0.0919\n",
      "Epoch 370/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0918 - val_mean_absolute_error: 0.0918\n",
      "Epoch 371/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.0824 - val_loss: 0.0914 - val_mean_absolute_error: 0.0914\n",
      "Epoch 372/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n",
      "Epoch 373/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.0824 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n",
      "Epoch 374/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0911 - val_mean_absolute_error: 0.0911\n",
      "Epoch 375/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0914 - val_mean_absolute_error: 0.0914\n",
      "Epoch 376/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0917 - val_mean_absolute_error: 0.0917\n",
      "Epoch 377/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 378/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0924 - val_mean_absolute_error: 0.0924\n",
      "Epoch 379/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0911 - val_mean_absolute_error: 0.0911\n",
      "Epoch 380/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0914 - val_mean_absolute_error: 0.0914\n",
      "Epoch 381/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0907 - val_mean_absolute_error: 0.0907\n",
      "Epoch 382/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n",
      "Epoch 383/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 384/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0910 - val_mean_absolute_error: 0.0910\n",
      "Epoch 385/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0914 - val_mean_absolute_error: 0.0914\n",
      "Epoch 386/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n",
      "Epoch 387/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0912 - val_mean_absolute_error: 0.0912\n",
      "Epoch 388/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0912 - val_mean_absolute_error: 0.0912\n",
      "Epoch 389/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0914 - val_mean_absolute_error: 0.0914\n",
      "Epoch 390/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0914 - val_mean_absolute_error: 0.0914\n",
      "Epoch 391/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0914 - val_mean_absolute_error: 0.0914\n",
      "Epoch 392/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n",
      "Epoch 393/512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0822 - mean_absolute_error: 0.0822 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
      "Epoch 394/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0913 - val_mean_absolute_error: 0.0913\n",
      "Epoch 395/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 396/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0822 - mean_absolute_error: 0.0822 - val_loss: 0.0914 - val_mean_absolute_error: 0.0914\n",
      "Epoch 397/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0911 - val_mean_absolute_error: 0.0911\n",
      "Epoch 398/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0822 - mean_absolute_error: 0.0822 - val_loss: 0.0909 - val_mean_absolute_error: 0.0909\n",
      "Epoch 399/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0908 - val_mean_absolute_error: 0.0908\n",
      "Epoch 400/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0822 - mean_absolute_error: 0.0822 - val_loss: 0.0917 - val_mean_absolute_error: 0.0917\n",
      "Epoch 401/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0822 - mean_absolute_error: 0.0822 - val_loss: 0.0919 - val_mean_absolute_error: 0.0919\n",
      "Epoch 402/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0907 - val_mean_absolute_error: 0.0907\n",
      "Epoch 403/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0918 - val_mean_absolute_error: 0.0918\n",
      "Epoch 404/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0822 - mean_absolute_error: 0.0822 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n",
      "Epoch 405/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0822 - mean_absolute_error: 0.0822 - val_loss: 0.0909 - val_mean_absolute_error: 0.0909\n",
      "Epoch 406/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0905 - val_mean_absolute_error: 0.0905\n",
      "Epoch 407/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0822 - mean_absolute_error: 0.0822 - val_loss: 0.0902 - val_mean_absolute_error: 0.0902\n",
      "Epoch 408/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0822 - mean_absolute_error: 0.0822 - val_loss: 0.0907 - val_mean_absolute_error: 0.0907\n",
      "Epoch 409/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0822 - mean_absolute_error: 0.0822 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 410/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0822 - mean_absolute_error: 0.0822 - val_loss: 0.0919 - val_mean_absolute_error: 0.0919\n",
      "Epoch 411/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0822 - mean_absolute_error: 0.0822 - val_loss: 0.0918 - val_mean_absolute_error: 0.0918\n",
      "Epoch 412/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0822 - mean_absolute_error: 0.0822 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 413/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0822 - mean_absolute_error: 0.0822 - val_loss: 0.0919 - val_mean_absolute_error: 0.0919\n",
      "Epoch 414/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0822 - mean_absolute_error: 0.0822 - val_loss: 0.0914 - val_mean_absolute_error: 0.0914\n",
      "Epoch 415/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0822 - mean_absolute_error: 0.0822 - val_loss: 0.0912 - val_mean_absolute_error: 0.0912\n",
      "Epoch 416/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0822 - mean_absolute_error: 0.0822 - val_loss: 0.0911 - val_mean_absolute_error: 0.0911\n",
      "Epoch 417/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0822 - mean_absolute_error: 0.0822 - val_loss: 0.0918 - val_mean_absolute_error: 0.0918\n",
      "Epoch 418/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0822 - mean_absolute_error: 0.0822 - val_loss: 0.0904 - val_mean_absolute_error: 0.0904\n",
      "Epoch 419/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0822 - mean_absolute_error: 0.0822 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
      "Epoch 420/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0822 - mean_absolute_error: 0.0822 - val_loss: 0.0912 - val_mean_absolute_error: 0.0912\n",
      "Epoch 421/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0822 - mean_absolute_error: 0.0822 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n",
      "Epoch 422/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0822 - mean_absolute_error: 0.0822 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n",
      "Epoch 423/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0822 - mean_absolute_error: 0.0822 - val_loss: 0.0913 - val_mean_absolute_error: 0.0913\n",
      "Epoch 424/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0822 - mean_absolute_error: 0.0822 - val_loss: 0.0910 - val_mean_absolute_error: 0.0910\n",
      "Epoch 425/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0822 - mean_absolute_error: 0.0822 - val_loss: 0.0907 - val_mean_absolute_error: 0.0907\n",
      "Epoch 426/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0822 - mean_absolute_error: 0.0822 - val_loss: 0.0935 - val_mean_absolute_error: 0.0935\n",
      "Epoch 427/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 428/512\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.0822 - mean_absolute_error: 0.0822 - val_loss: 0.0908 - val_mean_absolute_error: 0.0908\n",
      "Epoch 429/512\n",
      "685/685 [==============================] - 4s 6ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 430/512\n",
      "685/685 [==============================] - 4s 6ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0911 - val_mean_absolute_error: 0.0911\n",
      "Epoch 431/512\n",
      "685/685 [==============================] - 4s 5ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0906 - val_mean_absolute_error: 0.0906\n",
      "Epoch 432/512\n",
      "685/685 [==============================] - 4s 5ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0909 - val_mean_absolute_error: 0.0909\n",
      "Epoch 433/512\n",
      "685/685 [==============================] - 4s 6ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0918 - val_mean_absolute_error: 0.0918\n",
      "Epoch 434/512\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0913 - val_mean_absolute_error: 0.0913\n",
      "Epoch 435/512\n",
      "685/685 [==============================] - 3s 5ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0913 - val_mean_absolute_error: 0.0913\n",
      "Epoch 436/512\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0908 - val_mean_absolute_error: 0.0908\n",
      "Epoch 437/512\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 438/512\n",
      "685/685 [==============================] - 4s 6ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0919 - val_mean_absolute_error: 0.0919\n",
      "Epoch 439/512\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0908 - val_mean_absolute_error: 0.0908\n",
      "Epoch 440/512\n",
      "685/685 [==============================] - 2s 4ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0912 - val_mean_absolute_error: 0.0912\n",
      "Epoch 441/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 442/512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685/685 [==============================] - 3s 5ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0909 - val_mean_absolute_error: 0.0909\n",
      "Epoch 443/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0921 - val_mean_absolute_error: 0.0921\n",
      "Epoch 444/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n",
      "Epoch 445/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0909 - val_mean_absolute_error: 0.0909\n",
      "Epoch 446/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0907 - val_mean_absolute_error: 0.0907\n",
      "Epoch 447/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0911 - val_mean_absolute_error: 0.0911\n",
      "Epoch 448/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0914 - val_mean_absolute_error: 0.0914\n",
      "Epoch 449/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0922 - val_mean_absolute_error: 0.0922\n",
      "Epoch 450/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0911 - val_mean_absolute_error: 0.0911\n",
      "Epoch 451/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0909 - val_mean_absolute_error: 0.0909\n",
      "Epoch 452/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0904 - val_mean_absolute_error: 0.0904\n",
      "Epoch 453/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0912 - val_mean_absolute_error: 0.0912\n",
      "Epoch 454/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0906 - val_mean_absolute_error: 0.0906\n",
      "Epoch 455/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n",
      "Epoch 456/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0918 - val_mean_absolute_error: 0.0918\n",
      "Epoch 457/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0913 - val_mean_absolute_error: 0.0913\n",
      "Epoch 458/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0907 - val_mean_absolute_error: 0.0907\n",
      "Epoch 459/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0904 - val_mean_absolute_error: 0.0904\n",
      "Epoch 460/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0907 - val_mean_absolute_error: 0.0907\n",
      "Epoch 461/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0905 - val_mean_absolute_error: 0.0905\n",
      "Epoch 462/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
      "Epoch 463/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0903 - val_mean_absolute_error: 0.0903\n",
      "Epoch 464/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0923 - val_mean_absolute_error: 0.0923\n",
      "Epoch 465/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0912 - val_mean_absolute_error: 0.0912\n",
      "Epoch 466/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0912 - val_mean_absolute_error: 0.0912\n",
      "Epoch 467/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 468/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0903 - val_mean_absolute_error: 0.0903\n",
      "Epoch 469/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0918 - val_mean_absolute_error: 0.0918\n",
      "Epoch 470/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0913 - val_mean_absolute_error: 0.0913\n",
      "Epoch 471/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0912 - val_mean_absolute_error: 0.0912\n",
      "Epoch 472/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0912 - val_mean_absolute_error: 0.0912\n",
      "Epoch 473/512\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0917 - val_mean_absolute_error: 0.0917\n",
      "Epoch 474/512\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0917 - val_mean_absolute_error: 0.0917\n",
      "Epoch 475/512\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 476/512\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0909 - val_mean_absolute_error: 0.0909\n",
      "Epoch 477/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0906 - val_mean_absolute_error: 0.0906\n",
      "Epoch 478/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0917 - val_mean_absolute_error: 0.0917\n",
      "Epoch 479/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0908 - val_mean_absolute_error: 0.0908\n",
      "Epoch 480/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 481/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0908 - val_mean_absolute_error: 0.0908\n",
      "Epoch 482/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0908 - val_mean_absolute_error: 0.0908\n",
      "Epoch 483/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0921 - val_mean_absolute_error: 0.0921\n",
      "Epoch 484/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0902 - val_mean_absolute_error: 0.0902\n",
      "Epoch 485/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0905 - val_mean_absolute_error: 0.0905\n",
      "Epoch 486/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0913 - val_mean_absolute_error: 0.0913\n",
      "Epoch 487/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0912 - val_mean_absolute_error: 0.0912\n",
      "Epoch 488/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0906 - val_mean_absolute_error: 0.0906\n",
      "Epoch 489/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0911 - val_mean_absolute_error: 0.0911\n",
      "Epoch 490/512\n",
      "685/685 [==============================] - 2s 4ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0910 - val_mean_absolute_error: 0.0910\n",
      "Epoch 491/512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 492/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0911 - val_mean_absolute_error: 0.0911\n",
      "Epoch 493/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0912 - val_mean_absolute_error: 0.0912\n",
      "Epoch 494/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 495/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0921 - val_mean_absolute_error: 0.0921\n",
      "Epoch 496/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0906 - val_mean_absolute_error: 0.0906\n",
      "Epoch 497/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0906 - val_mean_absolute_error: 0.0906\n",
      "Epoch 498/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0904 - val_mean_absolute_error: 0.0904\n",
      "Epoch 499/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0918 - val_mean_absolute_error: 0.0918\n",
      "Epoch 500/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0905 - val_mean_absolute_error: 0.0905\n",
      "Epoch 501/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0904 - val_mean_absolute_error: 0.0904\n",
      "Epoch 502/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0914 - val_mean_absolute_error: 0.0914\n",
      "Epoch 503/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0922 - val_mean_absolute_error: 0.0922\n",
      "Epoch 504/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0922 - val_mean_absolute_error: 0.0922\n",
      "Epoch 505/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0911 - val_mean_absolute_error: 0.0911\n",
      "Epoch 506/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0918 - val_mean_absolute_error: 0.0918\n",
      "Epoch 507/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0819 - mean_absolute_error: 0.0819 - val_loss: 0.0912 - val_mean_absolute_error: 0.0912\n",
      "Epoch 508/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0819 - mean_absolute_error: 0.0819 - val_loss: 0.0906 - val_mean_absolute_error: 0.0906\n",
      "Epoch 509/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0899 - val_mean_absolute_error: 0.0899\n",
      "Epoch 510/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.0820 - val_loss: 0.0914 - val_mean_absolute_error: 0.0914\n",
      "Epoch 511/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0819 - mean_absolute_error: 0.0819 - val_loss: 0.0912 - val_mean_absolute_error: 0.0912\n",
      "Epoch 512/512\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0819 - mean_absolute_error: 0.0819 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a95be39ee0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Only save the best form of the model throughout the training process.\n",
    "https://towardsdatascience.com/deep-neural-networks-for-regression-problems-81321897ca33\n",
    "\n",
    "Notes:\n",
    "- look into pruning during training\n",
    "- explore this link: https://towardsdatascience.com/how-to-build-a-neural-network-for-voice-classification-5e2810fe1efa\n",
    "  - has dropout layers\n",
    "  - has graph to show performance over time during training\n",
    "  - has early stopping\n",
    "  - has layers to study\n",
    "- train with GPU somehow\n",
    "- better data preprocessing\n",
    "\"\"\"\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "# adjust values to your needs\n",
    "config = tf.compat.v1.ConfigProto( device_count = {'GPU': 1 , 'CPU': 8} )\n",
    "sess = tf.compat.v1.Session(config=config) \n",
    "K.set_session(sess)\n",
    "\n",
    "# checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "# checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "# callbacks_list = [checkpoint]\n",
    "\n",
    "# early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "\n",
    "NN_model.fit(train, \n",
    "             target, \n",
    "             epochs=512, \n",
    "             batch_size=256, \n",
    "             validation_split = 0.2, \n",
    "#              callbacks=callbacks_list, \n",
    "             shuffle=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e405e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180518, 64)\n",
      "(64,)\n",
      "(64,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABcqUlEQVR4nO2dZ3hc1bm27zVdXbKqbdmWuzFuGGNKQg09BPIRCIEUQgkJ6b2ehLRzUsg5OScVSEILaQRIIBBqQjfFNja49y6rW9JoNH3W92PNHo1m9szskVU80rqvy5ftqWtLM89+97PeIqSUaDQajabwsY31AjQajUYzPGhB12g0mnGCFnSNRqMZJ2hB12g0mnGCFnSNRqMZJ2hB12g0mnGCFnSNRqMZJ2hB10xIhBB7hRCtQoiSpNtuFEI8F/+3FEJsEELYku7/vhDi7tFfrUZjDS3omomMA/hMlvunAO8bpbVoNEeNFnTNROZW4ItCiMoM9/8Y+I4QwjF6S9Joho4WdM1EZg3wHPDFDPc/BPQCHx6l9Wg0R4UWdM1E51vAp4QQtSb3SeCbwLeEEO7RXZZGkz9a0DUTGinlRuBR4KsZ7v8nsB+4aTTXpdEMBS3oGg3cAnwEmJrh/v8AvgEUj9qKNJohoAVdM+GRUu4E/gJ8OsP9zwEbgGtHcVkaTd5oQddoFN8FSrLc/x/ApFFai0YzJIQecKHRaDTjAx2hazQazThBC7pGo9GME7SgazQazThBC7pGo9GME8asR0VNTY1samoaq7fXaDSagmTt2rUdUkqzyuaxE/SmpibWrFkzVm+v0Wg0BYkQYl+m+7TlotFoNOMELegajUYzTtCCrtFoNOMELegajUYzTtCCrtFoNOMELegajUYzTtCCrtFoNOMELegpSCn565oDBMLRsV6KRqPR5IUW9BS2tXr50gNv8ezWtrFeikaj0eSFFvQUfMEIAN5AZIxXotFoNPmhBT2FQDgGQH9IC7pGoykstKCn4A8p79wX0h66RqMpLLSgp+CPb4b6taBrNJoCQwt6CkZ2i09bLhqNpsDQgp5CQEfoGo2mQNGCnoKxKao9dI1GU2hoQU9hwEPXlotGoykstKCnYFgu/TpC12g0BUZOQRdC3CmEaBNCbMzxuJOEEFEhxBXDt7zRxx/WaYsajaYwsRKh3w1cmO0BQgg78CPgyWFY05hieOjactFoNIVGTkGXUr4AdOV42KeAB4GCb4CSSFsM6ghdo9EUFkftoQshpgL/D7jNwmNvEkKsEUKsaW9vP9q3HhESaYu626JGoykwhmNT9H+Br0gpcyqglPIOKeUKKeWK2traYXjr4SfhoQe15aLRaAoLxzC8xgrgz0IIgBrgYiFEREr592F47VHHiNCDkRjRmMRuE2O8Io1Go7HGUUfoUsqZUsomKWUT8ADw8UIVcwB/fFMUhqfj4o33rOb/ntlx1K+j0Wg0ucgZoQsh/gScBdQIIQ4CtwBOACllTt+80Agmeef+UJQyj3PIryWl5OWdnTrK12g0o0JOQZdSXm31xaSUHz6q1RwD+MNRhAApjz4Xvbs/jD8cHRT1azQazUihK0VTCISjVBapqPxoLZdD3X71mrpISaPRjAJa0FPwh6JMKnEBR1/+f/CIEnSdAqnRaEYDLegpBCIxqkvcwNELuhGha0HXaDSjgRb0JKIxSSgSG4jQjzIXvdkQdG25aDSaUUALehLBiBLeSaXDY7kcilsuAR2hazSaUUALehJGJF2d8NCHZ1NUWy4ajWY00IKeRCCi0guHa1M0WdCllEe3OI1Go8mBFvQkjAjdEPSjyUP3h6J0+UKUuh1IqVoJaDQazUiiBT0Jw+suctopctqPqie6EZ3Pri0Z9NoajUYzUmhBT8IQXY/TTonbflQRekLQ60oB7aNrNJqRRwt6EoboFrnsFLnsR5VuaGS4zK6NC7pOXdRoNCOMFvQkjPFzHoedEpfjqHqiN3f7sdsETdXKctERukajGWm0oCcxEKHbVIR+FCJ8qNtPQ7mHUo/qf6Y9dI1GM9JoQU/CEF33METoh474mVpVRJHTDoA/pLNcNBrNyKIFPYlAiod+NHnoh7r9TK1MEnQdoWs0mhFGC3oSg7JcjkLQI9EYLb0BJegu9SPWgq7RaEYaLehJGLaIx2GjyOUYsqC3eoNEY5KpVUV44hG69tA1Gs1IowU9iUAkitMucNht8Qh9aB66kbKYbLloQddoNCONFvQk/KFoIqIujme5xGL592A51N0PwJTKIopcxqaoFnSNRjOyaEFPIhhJEvR4D5ZAJH8hbu4OACpC9ziGtil6oKufz/x5XaKlr0Yzmjz21mF2tnnHehmaPNGCnoQ/FE1YJMXxyHooPvrBI36qS1wUuezYbAK3w5a3oK/a1cHD65vZ29Gf9/trNEfLlx94k9++uGesl6HJEy3oSQTCMTxO9SMpdqmCoP5g/oJ+qFvloBsUuex5D4r2BiLxv8N5v79GczREojF8oSgtvYGxXoomT7SgJ+EPm0To4fw3Rg8d6WdKRZKgO/OvOvXFTyTeoxyDp9HkixFMtPYGx3glmnzRgp5EIBzFnSLovjwjdClleoTutOMP51cp6gsZEboWdM3oMiDoOkIvNLSgJxEYFKEryyXf7JQj/WEC4RhTKwcE3ePMv3NjX1BbLpqxoTf+mevyhfSmfIExbgV9/YFunt3WltdzBnvo8Qg9z1z0RA56qoeet+Wi3rdPR+iaUSb5qrBN2y4FxbgV9J/9awf/+diWvJ5j5qHnG1kbOejJEfrQPHRtuWjGhuSrQm27FBbjVtBbewN5i3EgPJCHXuJWlku+EfrBpCpRA225aAqJ5CBCb4wWFo6xXsBI0eYNImV+VZ7+JEEfaoVnc3eAYpedymJn4rahWS46y0UzNiQHETp1sbAYlxF6NCbp7AsmJhBZJRiODVSKOoeW5XKou5+plUUIIRK3FTnzLyzq05aLZowwPnNOu6BNC3pBMS4j9M6+IDGZX0OsSDRGKBpLeOgOuw2Xw5Z3Hvqhbj9TkuwWGJqH3qc3RTVjhDcYwe2wUVfu1hF6gTEuI/Q2r/L9IjFJJGotSg9E4q1znQM/khKXPe9KUWNSUTKeIQycTmyKBrWHrhldvIEwZR4nDeUevSlaYIxTQR/4EBpCnYvkaUUGxXn2RO8PRTjSHx60IQoqQg9GYpY7N8ZiMvG+2nLRjDa9gQjlHgd15Z68N0VbegL8/pW9ee9faYaH8SnoSR9Cq7aLEUEbHjqo1MV8eqI3d6dnuAADPdEtFmkkZ9Zoy0Uz2ngDEco8jkSEno84P7TuIN98eBO7O3wjuEJNJsanoHvzF3SjIi5d0K1H6AdNioog/4wZYyO2stipI3TNqGNYLvXlbvpD0bwyrTr7QgC8eaB7hFanycY4FfQky8Viposxfq7ImWq5WP8wH8oQoXvyHBRtbIg2lHsIRWO6/FozqvT6w5R5HNSXewDyynTp6FPB1Hot6GPC+BT0IVgugUSEPvAjyTdCb+72Y7eJxBfBIN8xdMaGaEOFeh0dpWtGE28gQnl8UxSgpce6j25E6FrQx4acgi6EuFMI0SaE2Jjh/vcLId6K/1klhFg6/MvMjzZvELtN5YFbjW4NO2RQhO7Ob1P00BE/DeWexHsbGK9pXAXkwpcUoYMWdM3oYnjoRmCST+qiEaFvOdyr5+iOAVYi9LuBC7Pcvwc4U0q5BPgecMcwrOuoaPcGmVKpPoxWLRfjwzfIQ3fmtyl6pD9MTakr7faEh27xA+5NidD1xqhmtAhHY/jD0biHrj5/+aQudvpC1JS6CEclmw/3jtQyNRnIKehSyheAriz3r5JSHon/91WgcZjWNiSklLR7g0yfVAzkkeViJuju/CwXXzCS6AGTTL4euhGhT05YLjoXXTM6GMFDmcdBkctOucdhWdBjMUmXL8TZ8+sAWL+/e6SWqcnAcHvoNwCPZ7pTCHGTEGKNEGJNe3v7ML+1ors/TCgaSxJ0axF6MJxeWGR46FbTtvqCkUQf9WQGLJd8PXS1uar7uWhGC2+SoIO6SrQq6D3+MNGYZOGUchrKPdpHHwOGTdCFEGejBP0rmR4jpbxDSrlCSrmitrZ2uN56EK3xDJdpQ4zQU7NcojFJyGK1aX8oSqnbnna7YblYXUtfPG1xst4U1YwyxnCLMo9qLldf7qHFYnFRp089rrrUzbJplVrQx4BhEXQhxBLgt8BlUsrO4XjNoWJkuCQidIuboqYeujFX1GL5fybLpWgIlotNQE2pG9CWi2b0MIKH8niEXl/usZy22BHPcKkpcbFseiX7u/rp8oVGZqEaU45a0IUQ04GHgA9KKbcf/ZKODqOoKF/LxcxDL4nbJ/155I9nFXSLlovxOsZlr94U1YwW3rQI3U2bN0jUQtsKI8PFiNBBFxiNNlbSFv8EvALMF0IcFELcIIT4mBDiY/GHfAuoBn4lhFgvhFgzguvNiVFUNK0qP8slEI7hstsGpRwWJSL03IIaicYIRmKJk0AyHpf6MecToZe6HTjtNjxOm/bQNaNGmode7lHtqH25bRcjB7261MXiqRXYBKzTgj6q5GyfK6W8Osf9NwI3DtuKjpK23iClbgeVxU6EgKBlQY8O2hCFJMvFQmTtiz+mxMRDd9lt2EQehUWhgUi/zKPL/zWjx0CErj5/dUbqYk+QujJPxueBalstBFQVu7DbBPPqy7SPPsqMu0rRdm+QujI3QgjcDlte3RaT7RYgkbFiZQydkZlSamK5CCFUT3SLlos3kCTobof20DWjxkCEriyXhjyKizp8ISbFxRxg2bRK3jzQrTsvjiLjTtDbvAFqy9RmosdpffSbPxwd1DoX8hsUbQh6sYmgg7Jv8rNc1HuXeRw6QteMGr2BMG6HGu4C5FVc1NkXTGzkgxL0Hn+YvZ39I7NYTRrjUNCDictEj8O6oAfCUTyOwYJu2Ce+PCwXs7RFiA+Ktizo0USkX+pxJJp1aTQjjSr7H5iHW1PqwiasCnqI6qRK6WXTKwFYf+BIhmdohptxJehSStp6leUCqkjIepZLDE9KhF4Ut1z8eVguZpuioDJdrOehJ1suTm25aEYNbyBCedHAZ9hht1Fb5rYm6L4Q1UkR+ty6Mopddl0xOoqMK0HvC0bwh6NJgp5vhD74x1Hisj4o2oiizdIWIW65WK0UDUUSEXqZx6HTFjWjRm+8F3oyVouLOvqCVJcMROh2m2Dx1ArWH+wZ9nVqzBlXgm7koNeVK0F3O+15bYqmeuj5NNUymnhlEvT8LJeBCL1Ue+iaUcQbHz+XjJXiokA4ijcQSWtOt2x6JVuae3VP/1FifAl6PIow0qs8DttReeguuw2HTSTslGwY5fpmaYugLBe/BfsnGIkSjsqkCN1JXyhieR6pRnM0qGlFqYLuzpnlYlSEJlsuACdMqyQUjbG5WXdeHA3Gl6DHi4qSLRereehmWS5CCIosDrnIlrYIcQ/d0uvETwzxtZS5HUhpLXVSozlavIEIZe7BlktDuYfu/nDW4ChRVFSSEqFPqwL0wIvRYlwJers3JULPY1M0EI6lFRaB2uS00hPdF4wgxODmXslYTVv0pXjxRrSkbRfNaGAMt0imLjGKLrOP3pHUmCuZhgoP9eVu3QJglBhXgt7mDeJy2BK79B6n3XpzrlB6YRFYH0PnC0YpcTkQQpjeb9VDN4Q72XJJvl2jGSmSh1skYxQXtXoz2y5GhF6bIugQLzDSG6OjwvgS9N5AokoU8stD95tUioL1IRdqI9M8Ooc8LJf41UCpxzHo776gTl3UjCx9KX1cDBKj6HqyCboRoadP7JpfX8a+Th8hiwkKmqEzvgTdO5CDDtYtl3A0RiQmTe2SYqc1y6UvZN5p0aDIZbMUoaemPxpfrl4doWtGmNTGXAYNFqpFO30hPE5boro6mRnVJcQkHOr2D+NqNWaMQ0EfaCBkNQ99oBd6+o/DaoTeH4xkLCoCFaFHYpJwjmEZqZurZW7dQlczOqQOtzAoL3LgdtiyCrrKQXebWo4zqlXn072dvmFcrcaM8SXovYFEDjqoPPRgJJazOZARxZtG6Pl46FksF6tzRdM3RbWHrhkah7r9/PLZnZabY6UOtzAQQtBQkb24qKMvZDogHVSEDrCvQwv6SDNuBD0QjtIbiKRZLgDBHN6dEaG7TQXdYakfel8wkjFlEZLG0OU4ORj57KWu1CwX7aFr8uOhtQe59clt7LPYHCtThA5QX5Z9tmhnXzAtw8WgptRFicuum3SNAuNG0FNTFoFEoVAu28W4P2OEbiXdMGQ+INrA6hi6gQjdnnh/m0A36NLkzb4uJaB7LFodiQi9KP1zXJ9jWHRnXygtB91ACMGM6hL2actlxBk3gm4UFdWWJ0fohqBnj9DNxs8ZqAjdquUyPILudthw2NWvRghBqVuX/2vyZ39c0PdatDpSx88l01CuGnSZ2TdSqolGNWXmETpAU02x5SsFzdAZP4KeKPtPt1xyR+jZPfRQNGZpMzNT61wg0ckxV4MuM+tGTy3SDIX9nfkKunmWC6jUxUA4Rq8//XPYG4gQjsqMETooH/3AkX5Ls0k1Q6fgBH1Tcw+f/fO6NJFuM7NcjAg9R3GRETUXuUyyXCyMoYvGJP7w8ETofcFIIvfcQA250B66xjqBcDTRf2WPxcjYGwjjcdpw2tO/B/VZiouMHPSaDB46QFN1MeGopFmnLo4oBSfoPf1h/r6+mYfeODTo9tbeAHabGBQlDEToFjdFHeaWC2SPrBOdFi146LmuFnwm6Y96apEmXw7E7RaXw5ZXhG5mt0D24qJO38Bw6EwkMl2ynFxuf34XL+3osLRWjTkFJ+inzq5mSWMFv3lx96DLtzZvUE1XsQ3kwea9KWpSFDEwtSizoCYaalnIcvGHsp9czCyXUreeWqTJD0M4T545iYNH+i1VaZr1cTEwiosO96RH2Ikq0ZJsEboS9Ey56H3BCD98YivX372a57e351yrxpyCE3QhBB89YzZ7Onw8taklcXtqUREMpCFaFXSzTdGEVZIlQu9LyUwxw/qmaHo+u/LQteWisY6xIXrmvFpiEg4cyW27mA23MJhaVUSxy27aBrc93sclUx46qL0tj9OWMdNlc3MvUqpCvpvuXcPLO3WkPhQKTtCRkgurW5lRXcxtz+9K7LobfVySsWq5GGJttilqRN3ZeqJbsVzyKSxKjfTL9FxRTZ7s7+qn1O3ghOmqfa0V28VsuIWB3SZY0ljBOpOuiUaEXpVlU9RmE8yYVJIxF/2tg+p17//oqcysKeGGe1bz6u7OnGvWDKbwBH3dfdh/cyZfWhbhzYM9vLq7C1B56EabTwNDRHNNSzGmGpmV/htWSbZc9Fzj55JfJ3dhkYnl4nHoXi6avNjX6WP6pGJm1iirY48lQU8fbpHMsmlVbG7uTbvi7ewLUVnsNN1MTWZGdXHGCH3joR4ayj3Mqy/jvhtPprGqmOvvXs2avV05160ZoPAEfcE7we7iwvAz1JS6uP2FXYSjMTp9IZMI3ZrlYkToqROLYCDqzpaLbnjo2SpFjXmlQ4nQyz1OQpFYwY/x8gUj/OLfOxIR3XjGarn9SLGvq5/pk4qpKnZS7nFY6qNiNtwimROmVxKJSTY1D26F2+kLZs1wMWiqKWFfZ7/p9K0Nh3pYNLUCUNkyf7zxZBrKPXz4rtXsbOvL+doaReEJevEkmH8xjg33c/0pU3huWzsvxf225D4uMCCiOUv/I1FcDtugDdXE2yXSFrNtiub20B12Gy579o6LsZjEF0pPfywdJw267nt1Hz95ajtffWjDmAueFf7zsc38z1Pb8n7ethYvi7/9FKvHKLqMxSQHu/zMqC5GCMHMmhL2duT20LNtioIaJwewbn/3oNs7slSJJjN9UjHBSCwt9bEvGGF3h4/FcUEHNVTjnutX0heM8Ny2tpyvrVEUnqADLP8g+Lu4tnorJS47//XYFoC0TVGrEXogFM04achKHrovx4DogfXYsm6uGq9TZuKhQ2E36IpEY9yzai+lbgdPb27lkTebx3pJWXlyUwu/eXEPj244nPdzn9nSSl8wwg/+uWVMTlwtvQFC0RjT410Om2pKcloumYZbJFNX7mFqZVGaj97ZZzFCNzJdUk4umw71ICUsaawYdHtjVRGlboduu5sHhSnos86G8kZKNv2Rq1dOZ0f8kiyz5ZIrD918/BwM5KFnFXQLHjooHz3bySVT+qPxJSvkjdHHN7bQ3BPgJ1cuZdm0Sr79yKZE/51jjSO+EN/420ZA5V3nK8qrdnXgsAne2N/Nv7eOfnRppCzOmKQEtKm6hOYef9bPXrY+Lsksm17J+pQIvdMXypqDbmC00U310TccUhbOoqmDBV0IwZRKjy5GyoPCFHSbHZZdAzv/xY1LXTjiVkmq5WK3CZx2kdtDD2eO0D1OG0Jkt1yMDonFGV7DoCjHGLpM6Y+G5dJbwKmLv3tpD03VxZy/sJ6fXLkEXyjKtx7eONbLMuWWRzbR3R/iPcsb6Q9FTcvdMxEIR1mz9whXr5xOU3Uxtz65zdQzHkn2dynBNAR0Zk0JUg4UG5mRrY9LMidMq+RQt5+2eBVqOBqjuz+cNQfdYEplEU67SMt02XCoh8kVHmpNesFMqSyiuTtzU7BMrNt/hL+tO5j38wqdwhR0UIKOpGH337hs2VRcDpvpZZ8aQ5e7UtQsBx1UlFDszN4TXQ23sJt68IPW4rRnt1xShlsYFLrlsnbfEdYf6Oa6t83EZhPMqSvjs+fO5fGNLTz2Vv6WxkjyxMYWHnmzmU+dM5dzFtQB0GxSTJOJdfu7CUZinDGvls+dN4+tLV7+8dbQ7aXu/hDX3vk6968+YPk5+zr7cdgEkyuUBdlkIdMlWx+XZE6YXgmQsF26LFSJGthtgmmTihMnHIPkDdFUlKDnH6H/8tldfOWBDZamjY0nClfQJ82EmWfA+vv4zqXH8eDHTjNNm3JbGBSdaZ6oQbE7+xg6XyhCcQ67BXIPis5k3RhfMqubopube00r+saKO1/aQ7nHwRUnNiZuu+n0WSxprOCbD288ZrJeunwh/uPvGzh+SjkfP3s2kyszV0dm4pVdHdgErJw5iXctmcKChjJ++vT2nM3dzPAGwlx7l6qc/HVSzUUu9nf1M7WqKNGxc2aOKk1I7oWe/XN8/JQKHDbB+rigdyT6uOQWdFD2T7KH7g2E2d0+eEM0mamVRXT6QpZnAxvsaPMSisYmXC574Qo6wAkfhCN7KT38KosbzT8Qaq5o9g9DMIuHDrmnFvUFo1lTFg2KcozE68sYoRtTi6xZLp/84xt8/aENlh470hw80s/jGw9z9crpg05UDruNW69YijcQ5pZHNuV8HX8omrW4azi45ZFN9PjD/OTKpTjtNqZUFAHkdcm/alcni6dWUFHkxGYTfOmC+ezt7OeBtfld/vtDUW64Zw0bD/VwyZLJ7OnwscmkStOM/fGURYOKYidVxU72ZMl0GZhWlN1y8TjtLJxSzrr9RwCVgw5kHG6RipGLbpycjGPK9P2dEj+p5hOl+0PRRKXsC9vHtuK0pz88qntfhS3ox70L3BWw7r6MD3E7bAQt9EPP5KGD2hj1Zc1Dj2RNWTQocuWI0DNkyxgCb9VyOdIf4uVdncfE5eY9q/YihODa05rS7pvfUManzpnLo28dZu2+7Cl+1939Ojfes2aEVglPb27lH3Gr5bjJ5QDUlrmx24TlCN0XjLD+QDenzq5J3HbOgjqWT6/k/57ZYTnKDEaifPS+taze28VPr1rG9y5bhMMmeNSiPbWvsz/hnxs01ZRkrRa1arkALJtWyVsHe4jGVB90yN5pcdA6qkvwhaJ0xE8EGw6qDdFMEfpQTqq72vuQUgVzY90X5iP3ruHLD7w5au9X2ILuLILFV8Dmh8HfbfoQK4Oic1ouLjv+cPY89GzTigyKcnjofYksl8FrcTlsuB02y2d6XyhKKBJj1c6xvdzsC0b48+sHuHjxZKZUFpk+5sbTZ1JZ7OT253dnfJ3Ve7t4dXcXa/Z15X3pbZUnN7VQXeLi5rNmJ26z2wT1ZW4OWxST1Xu7iMQkp82uTtwmhOBLFyygpTfAfa/uy/ka4WiMT/1xHS9sb+dHly/h0qVTqCpx8bY5NTz6VnNO26WnP0yPPzwoQgdlu2SzXKxuioLy0ftDUba3epMidGuWS2qmi7EhmumEYHxu8onQt7d6AbjixEb2dPjGbFKSlJKNzT28trtr1NJXC1vQAU74AEQCsPFB07s9Fjz0QM4I3Z49Qg9lnyc6aC1ZrhYMS8GsWq/M47RU/h+OxhKd9f49xgUZ968+gDcY4Ya3z8z4mGKXgw+dMoOnt7Syq928IvC253YBEI7KRIrbcNPc7Wd6dXHaPszkyiLLm6Kv7OrEaResaKoadPups6s5fW4Nv3h2J09uasn45d7V3seN96zhqc2t3PKuhbz3pGmJ+y5ZMpmDR/y8eTD78e+LbzhOj6csGjTVlHC4J5AxoMgnQj9hmjq+9Qe66egL4bLb0monMjHQdVFZIhsP9WSMzgEaKjwIQV656Ntb+3DaBdee2gTAC2MUpbd5g/SHonT6QjSbtB0eCQpf0KecAPWLYN3vTe9WHnruLBezAdEGxa5c2SnZh1sYFLmyV4r2BSLYhHlPGasNupJbFDy7tW3MKjJjMcndq/Zy4owqlsUrDDPxodOacNlt/PbF9Ch9W4uXf21t40OnzgDgjX1HRmK5NHf7Ta8iJld4OGzxy7hqVycnTKsyvVq75V0LqS5x8dHfr+WK214Z1KOkzRvgG3/bwPk/fYE1e7v47mXHc93bBp8Ezz++AZfdxqM5CrIM79jMcoEBwU8l23CLVGZUq5YC6/YfiQ+HdiFE9gwvg6lVRdhtgn2dPnoD4bQK0VScdhv1Zfnlom9v9TK7tpQ5daVMm1Q0ZrZLclbRWyZNzUaCwhd0IWDR5dC8DvrTfViVtph7BF22CL3E5cjRDz37+DmD3JaL6uNi9uWwOrXIWOeJM6o43BNgy2FvzueMBNtavezv6ueqpCgzEzWlbt5zYiMPvnEordjo9hd2UeS087lz59FUXczaERB0KSXNPQGmmgj6lMoiDlsoLurpD7OxuYdTk+yWZObUlfHkZ8/gB5cv5kBXP1fc9gofuXcNtz65lbNufY6/rD7AB06ezvNfPpsPxSPLZCqKnJwxr4ZH3zqcNa/dKCoys1wgc9fFbMMtUhFCsGxaZTxCD1q2W0AJdGNVEXs7+9l0KPuGqMGUSk9eqaPbW73MrS9DCMGZ82pZtavTUj/44WaQoI/QlWUqOQVdCHGnEKJNCGFaBSIUPxNC7BRCvCWEWD78y8zB5GXq79b0JVr30DP/KIpyRuh5eOjhaEZx8Jl0WjSwOrXI2Ah95+LJADw7RrbLa/F0sdMyCFwqHzl9FuF4ewCDQ91+HlnfzFUnTaOqxMXyGVW8sf9IVnHd0erNOxum0xciFIkxpcKTdt/kCg+hSCwxlScTr+7pREp425yajI9x2G1cvXI6z33pLL54/jxe2dXJL5/dxdnz63jm82fyncsWZd1cvGTJFFp6A6zdn/mktr+zn5pSd9oVY1ONEvhMmS65+riksmxaFTva+tjX2W+pqCiZ6ZNUpsuGQ91A5g1Rg3yKi3zBCAeP+JlXVwrAmfPq6A9FWZNj030k2Nvhw2W3sXByeaI98EhjJUK/G7gwy/0XAXPjf24Cfn30y8qT+kXq75Z0QXfnsFzC0RjRmMweobszR+iZGmqZYQyKztQszBdK77RoUOp2WMpDN7z+pppiFk+t4F9bWnM+ZyR4bU8XUyuLaKwqzv1gVDXjBQsb+P2r+xKCfOdLe5CojVNQVx0dfaGErZBKc7efC//vRc757+d4eP0hy3aTcTk/2dRyUbfl2hh9ZVcnHqctp70Eat/gk+fM5aWvnM3zXzqLX75/ecISyca5C+txO7LbLvu6fEyflH4cZR4nNaWujBF6tuEWZpwwvRIpYXeHL68IHZSPvqfDx4ZDvUyp8ORMeZxaVcShbr+l36fRmXFufRmg9i+cdjEmtsvuDh8zqotZNl1lBY2G/ZlT0KWULwDZTm+XAfdKxatApRBi8nAt0BJl9VBSmzFCz9Z21vC0s2W5FMU3M80udY0+6VYtF8g8/agvixdvdWqRceIpdjk4Z0Ed6w50J6r5RgspJa/t6eLkWZPyet5NZ86ixx/mL6sP0N0f4k+v7+fSpVMSJ4Xl8WENmWyXpze3Eo1JKotcfObP67nqjlfZ2pI7d9sQdHPLJZ4HneOSf9WuDk5qmoTLYd3FrCx2JWZtWqHU7eDs+XX8c2PLoPGLyezv7M/4mk3VJezJkPHRm2W4hRlLk05cVlMWDWZUF+MNRFi1syOn3QLq92LlKgkGMlzm1asIvdTtYMWMSTy/bfQFfW+Hj6aaEpY2VuANRDIO9xhOhsNDnwok1yUfjN+WhhDiJiHEGiHEmvb2Yf4B1y+ClvRimlyl/4nxcybzRA2MNEKzDc3+4ICA5iLXGLpsXnyp24E3j03RkrigS8lRtR/d2+Hj0TxL13e09dHlC3HKTGt2i8Hy6VWc1FTF717aw10v76U/FOWjZ85K3D+vvoxStyOjoD+1uYU5daX88zOn84PLF7Oj1cs7f/YS3/nHpowCCHAoHn2bb4qq28yGIxu0e4Nsb+3jtNmZ7Zbh4pKlk2n3BnltT3pKajAS5XBvIM0/N8iWi+4NhHMWFSVTUeRkdq06cVitEk2sI37C6fSFctotMJCLfuhIbh99R1sfLodt0EntjHm1bG3x0to7OpkmANGYZF9nP7NqSlg8tRJgVGyX4RB0s+1t02+PlPIOKeUKKeWK2traYXjrJBoWQftWiA6OYnNVigbiQ5s9WSKrorhYm9kumao7zV8nt6BnGmNXHs9yydXoKRGhu+0snlpBTan7qDr+3f7CLj79p3V55X8b/nm+ETrATWfM5lC3n5//ewdnz69lQUN54j67TXDC9EreSOn2B2pT8tXdXZy/sB67TXD1yuk8+8WzuGJ5I3e9vDfrSe1wtx+P00ZVcbqgVZe4cNltWSP0V/LcLzgazllQR5HTblpkdPCIHynTM1wMZtaU0OYNmu4x5Ouhg/LRIftwaDMMPx/SOyyakU8u+rYWL3NqS7En9VU6c57SmtFMX2zu9hOKxmiqKWFefSluh423cqScDgfDIegHgeRUhkZg9Jtd1y+GaAg6dw662eO0E4lJIhl6aRg56kXZInSjJ7pJLnqmlrdmeHJaLhFKM3ypyjxOpDQ/qZitp9TtwGYTnD2/lue3tw+plwjA1hYvMZm9D0gqr+7poqHckzFSzMY7FtQxu7aEmISPnTk77f7l06vY1tKbZj/9e5uyW85bWJ+4rbLYxdcvPg4gY447KDtlSmWRaXaRzSZoqPBk9dBf2dVBmcfB8VPKMz5muCh2OXjHcXU8sbEl7TO9v9M8ZdGgKUtPl1zj58wwGnXl66E3VhVj/KitROiGFWYlF31HqzdhtxgcN7mM2jL3qProRobLzJoSHHYbx08pT1TFjiTDIeiPAB+KZ7ucAvRIKUe/hV6D+cZoYlB0ho3IbOPnDIzht0aZczID5frWPfRM0a7ZPFEDQ+hz5aL3Jzx09V7vOK4ObyAypHQ/KSXbW5QnaXUMmJSS13Yr/9xqbnIyNpvgO5cu4uazZrNyZnqEf+KMKmIS3jww+Mvx9OZW6srcLG2sHHS7lT4mh7oDict6M1QuemYxWbWrk5NnVieaYY00lyyZQpcvxLMpvrBRETkto+Wibk8dMBGOxgiEY3ltigKcv7CeC46vt7QRnIzHaWdKRRFTK4ss9YApL3JQ4rLnzHTxBsI09wQSG6IGRvriizs6slpvmTjiC/Hdf2zOmumWSrKgAyxprGRjc8+Q3j8frKQt/gl4BZgvhDgohLhBCPExIcTH4g/5J7Ab2An8Bvj4iK02GzXzwOaE1sE+eq6pRcbt2SL0hvjw6ZYeE0E3OiRa8dCtWC5Z0hYhdz8XI0I3PP23z63FaRdDsl0OdfvxxT/EO1qtCfruDh8dfUFOztM/T+btc2v4yoULTE8Iy6ZXIsTgjdFAOMpz29o5b2G9aQvjXH1MVFFResqiQba0udbeAPs6+zllCPbSUDlrfi0za0r4yoNvJaJyUHNEi112ajOIZKYIPZ8q0WTqyj3c/sEVVBbnF6EDXLiogXefMMXSY9Wgi9xtdI1BN/NSBB2Uj97jD/PmEHzsxzYc5s6X9/B6HiMF93T4KHbZE0N3ljRW0B+KZr1SHA6sZLlcLaWcLKV0SikbpZS/k1LeJqW8LX6/lFJ+Qko5W0q5WEo5ch2UsmF3Qu2C9AjdkV3QB7JcMv8oDEE321Tpy9Dy1oxsWS7BSJRwVGbJQzc6LuaO0D1OW8JDLHU7OHlm9ZAEfVs8OhcCdlr8IL62W33oh+KfW6Hc42ReXdmgXOxVuzroD0U5//gG0+dk62MSjERp9wYz9poBFaG39gZMoyvDF803Sj0aPE47d374JGJSct3dr9PTr+ynA/Eui5mujErcDurK3Gl90fPp4zJcfPOShXzpggWWHz/FQguGHfEMl/kmgn76nBqEYEjZLm/Gqzz35CHGezp8NFWXJH4Xxni9kfbRC79SNJmGRWmpi27DcsmQ6WLcni1tsbLYicthMxX0ZM86F54sWS4JLz7DlcJAx8XsqYt9JhurZy+oY2db36Bozgrb4l+Qk2ZMYpdFy+W1PZ3UlLqZZSGveqgsn1HFuv1HEhvET29updTtyBglZ+tj0hq/6soq6JVFRGIy0fs7mQ2HerAJWDgK/nkyM2tKuP0DJ7K/q5+b/7CWcDTGvs7+nPsWZlcrQ43QRxMrEfr21j6KnHYaq9J/l1UlLo6fUj6kAiOj93uuuazJ7O30MbN24Dswq6aUEpd9xDNdxpeg1y+CvlboGzgLW7VcyvyHYe098NcPw89OgENvJB4jhKC+3E2LiaD3J2WV5MKwXMzWkmsuablFy6U/FE1bizF55/kd+UUn21u8TK0s4oTplezu8GXcWDY4Wv/cKifOqMIbiLCzvY9oTPL05lbOml+LO8M+iFG0YxalH8qSg25gVJCaCcrGQz3Mri21lLY63Jw8q5ofXr6EVbs6+cbfNqT1QTdjTl0pWw73JqJ6sD7cYiyZWumhoy/7oIvtrV7m1JVmnBw2s6aUgxZSH5PxBsKJq9PdFgU9FIlxoKs/0W4B1N7QoqkVOkLPC2NjNClKNwTdtLgoHGDehp/wb9fnmf77k+Efn4Z9r4C3FVb9bPBLl3tMc5H78vHQs1guudIfrW6KmqU+NlUX43LY2J9nG9GtLSpjYHZdqfqQ5vgy7O/qp6U3wCkmm5nDyYkzBgqM1h84QkdfKKPdAiSuFsx8dEOks1su8WrRlN+/lKr7o5VMjZHiPSc28ulz5nD/moMEI7GMGS4GHzh5Bv3hKD//947EbVaHW4wlxu8nW6M01cOlNOP9jVUqys9nY3LDwR6kVMVTViP0A0f6icmBDVGDpdMq2Xy4d0T7yowvQa9frP5OFnRHBsulrw3uuYSFu+9kn6yn/+zvwcdfhS9shRXXwZZ/KGGPU1fuoc1kSr0vGKHIaR+U95qJgcKi9F9orgjd6tSifpM2BEII6srcpuvPRDgaY3e7j3kNZcyJ98XIleky4J+PbD52U3Uxk0pcrN13hKc2t+K0C86an7muITFT0+SEZmSvTDbp42KQaWpOa2+Qdm/QUrXjSPK58+bxrqVqgzFXC4GFU8q58sRG7nllbyIrplAsF8ici97jD9PaGzTdEDVorCoiHJW0ea0XGBmzUy9ZMplD3f6BK4T2bfDKLyGW/l3e065+rqm/i8VTKwhFYrS98Dvotj4jNh/Gl6CXVEPZ5EEbo6aWS8tG+M050LKRJ4+/levCX0Gc+gmoO07tAK64HmIReOPexFOMCD21H4PVPi6gpieBuYeeiNAzfKlKXHaEyD1X1BeKJFIWk6kv99DWa13Q93X6CEVjzK+3Luiv7ulkUomLuXWZo6ThQAjB8ulVvLHvCE9tauWUWdVZo8tSt4OaUrdphH6oO0B1iSvrHkpFkROP05YWHRq92ccyQgf187j1iiX8/OoTONXCyfQL58/HYbPxoye2AmOzKZovuXLRs22IGhgtJPKxXdYf6GZmTUmid82+zn7o3AV3XwJPfh1e/O+05xjWXuo+0tLGSo4T+5jywpfVyWAEGF+CDlB/vKnlkojQtz0Od16gBPv6J9hUeRYwILYAVM+GWWfD2rsgqgS0odyDPxxNGzJhdfwcKB8tU+Vqrs1VIQSlbkfOIRf9waip/aMidOuRybYWJd7zG8oo9zipL3dbitBXNo2sf26wfIby9fd0+LLaLQYza4rT8q8hcx/0ZIQQTKkoSstFH6sNUTM8TjvvWjrFUi58fbmHj545i39uaGHtvq6CiNDry9Wgi0wR+vZWoylX5mBiWnyz9ECG5m6pSClZf6CbZdMqmVWjXrf5wC74/buVfsw9H577L9jzwqDn7e7wUVHkTNSvDLy/h++776XfXgZnfcXSGvJlHAr6InU5FFGNfBKFReEovP4b+NPVUDMXPvIsTFlGMBzF7bClb6ScdAP0HoIdT6qXjV+St6VsjGYr1zcjU0/0vqCKkrJF++UeZ85N0b5gxHSDNl/LZVtLLzYBs2vVB3lOXWnW1MWDR/o51O0ftXzsE6cPTAU677j6LI9UZGpMlSsH3WByZfqgi7HcED1abjpjFvXlbr7/2BZ6/GGKnHZLwy3GCpfDRl2ZO4ugeylx2bNvbsfvsxqhH+4J0O4NsmxaJU01xZTTx5LnrldzFz7wAFxxF1TPgQduGGTP7u3wpfnnAGLjg5zIFn7n/iAUVaXdPxwcu7/BodKwGGJh6NgODETodu8BeOJr6qz64X9CuWoI6Q9HzYuK5l0EZVNg9W8BqI8XCKRmumSr7jTD6ImeijFPtDSLOJS6HQnhz0R/yPwEU1fuwRuIWO7Jsq3VS1NNSeLnN6e2lF1tfRlbgI6Wf26wpLESh02wdFolDVn8b4OmmhLavcFBm8pSSksROqiN0dTy/7HeED0ail0OvnD+fNbt7+bRt5qP6ejcIFuB1/ZWL3PiQy0y4XGqQp+DR6xF6Ea64tJplZTZQvy+6L+p6N8P7/sDTD0R3KVw5T0Q9MKDN0BMfbf2mAl6sA+e/iYtJQv4ZfepIzYbd/wJev3gTBejsOi47beDsMElPwXXQCZAIBw1L/u3O9Tm6K5/Q+euhGikZrqoTUhrlguoro7meei5WwhYGXKRydOvjZ+QrPro21v7WNAw4EfOqS+jLxgxTd0ElX9eWezM6mEOJ0UuO1+8YD6fPXeupcfPNMl06Q1E8IWiWcv+DaZUeGjzBhKpm629gWNiQ/RoeM/yRo6bXE5rb7CABD2z5TIv197N8z/m24676Oq0lr775oFuXHYbx1WE4f5rWSx38NPyr8CsswYeVL8QLvkf2PsiPPcD/KEoh3sC6YL+wq3gPczek79DKCbYfDh3W+ehMP4EvXoO2N2JVrpup40ZooW5zY+ozc6KwZ19/eFY5rL/5R8CmwPW3El9vFo01bZQFkd+EXrAxHLxBSO4HbasHmiuuaLGgGiz4iSjBNmKj+4PRdnb6RuUMTCnNvPGqJSSV3Z3clLTpIw5wCPBx86czdnz6yw91ih7T049s5KyaDC5soiYhNb479/IJy7UCB1U98r/eKdqXnYsb4gaTK00H3RxxBeioy/I/IYswUSgF164lYv9j/KDlo/Atieyv1moH8/2h7mv5Ke4/3cB7Hyav0/9An/uW5b+2GXXqGH1L/yE9nWPAikpix071Sbo0muYsfRMgBFr1DX+BN3uUNkq8Qjd7bDxWcdDRG1OePvn0h7uD0UHb4gmU9YACy6B9X/AQ4iKImdahO4LRrLaJKlktlxyWzelOTz0/viJwuwEU1dmtC/IHaHvbOtDysEZA9kyXba39nGgy581dXCsGWhMZSboFjz0+BXa4fhzcm6IRkZ3qMhQeducGt67opFTRskqOxqmVHgIRmJpA1uMoRapTbkGse2fEA3xVNOX6IyWwJ+ugoduGphDHAnCobXKYn3wI8ifzOVz3T9ggdwNp9wMH3uZjvlX0+kLDSrKSnDRrVC3kGmPX8tvnD9hsX+1SmmUEp74Kjg8cO63aSj3MK++dMQsl2P/OmsoNCxSZ2ApEe3buMz2Mq/Vv59Ty9I3z4KRDB66wUk3wOa/w6a/0VDemGY59GeZMmRGkcueHmX7Orhy99cJOs4Czsv43FyDogcahZmlLVqP0I2S/+SIp6bURUWRM9EAKZmnNrUA1jYnx4pil4OGcs+gjdHm+Mk520aaQSIPOv6cjBuigV545haV8nrFXbDw0mE6gpHjx1csHeslWGIgFz0wqEuj0XArtW3uIDY+BOWNdB73AT6xdTFvnPkmZav/D3Y9C+VToHWT2nsDKK6hZ9Yl3PzWbK669H28e/l0AGZ2qY3PPZ0+lhVXDn59VzFc+whr/vJfLNv3ALVPfAhemwmzz4adT8P5/wll9Qjgqc+dORw/DlPGX4QOykfv71BtAJ77Af3Cw3M115g+1B/K4KEbNJ2uOjmu/i318SZNBlLK+BzQPDx0syyXVT9jmfcFfhL8Lvzre4lUyVTKcqQtDrQhSD/BVBW7cNiEpUyXbS29aVNfhBDMrSs1jdCf3tLKCdMrqStPiXR9HYmNomOBppritAjdaReWRqiZRehpdsv2p+BXp8Dau6GkDh75JHTvH7b1T3SmVnpYKbZQ9PKPlI2Baltw+/O7Wdk0KdFELw3/EbUXdvy7aZxUQhgHm+d/Am56TnngnnI49RPw3nvhsxvgSzt5fNY3eCV2PMumD1y5GDbKno4M2V4lNfyl7Foudd4O7/mdusJfcyfUzIeTPzqcP4qMjM8I3dgYffNPsPnv/MV2JUek+dk7EIlSXpTFPxQCTvoIPP4lbqz+DV/tfU/iLn84Skxa67RooOaTJolcfxes/h2ved5OnyjhHS/+BA68Bu/5rfpAJFFe5CQUiamNXKMQxt+tcmJLarI2+LLZBLVlbkubotta+5hbV5pW/TqnrpSnNw8eOt3c7eetgz18+cL5g1/k0Bsq3/+cb8LbPp3zPUeDmTUlPLlpYP3N3X4aKjyZfX/DqxWCMo+TMreDwz2BxIZoYtqOr1NdVm+4X3X8fO+9UFwNt50OD96osqrsx8BXzdcJb9wDYT+c9TWwFUg8FwnBpoeYv+qX3O9+C7YA226Hkz7Cb0KX0dUf4p53Lcyc4bL1MRV9L7qcRvdAcdHJsxbDhx42fcr6/d1UFjsHtVKYPqkYm4Dd7ZlbAOzt8DGtthIWXwSLr1Ap1J5K1Q12FDgGPmUjgNHT5dn/Ak8Ff7NdxqwM3Rb9oWjW1rmAynbp3MkZr9/Oz2LriXQvxlE5Na/WuQZpHvprt0Goj3srrqa/ch7vOOHd8OjnlRhc8TuYeUbiocaJpzcQHhD0P71PTWn6+Gv4QjLreqwWF21v8XLanHRPdU5dKX9efYAuX4hJ8aKJZ7YogTx/YdLJJ9ALD1yvJkituw9O+xRk+rJ17lIbRud+W0VKI0hTdQldcQ+0otipUhaNDJetj8HL/6fWHvSqPyEvzDkPrvkLCMHkSg/N3f7EhtaSxgp1FfLrt6krwjO/Cqd/HhzxiP9d/6vS2Z77AbzjmyN6bFlp2aA+Z2/9FaLxE3osrH7mVgj7oWsP9DZD4wooqjz6NQV6QUYz52PHonB4Pex4WkW5fa3Ya+ZzS+wjVC+9iE+7/oF8/XZuiN3L3BnXsag+s1XJxoegcgZMWc6UeJZSrlz0Nw92s7SxctBJwuWwMW1ScdYmXXs6fJybbD3Wzs/42JFgfAp6URWUN0LvQTjzK0TeqMjSbTGWtewbUGfXi3/MS4GZLH/zFsQdZ8CVd9Nfthwg42BnAJ76JlRMg5NvUktzJVkugV71RVtwCVsONrLQ7VA75lNOgPuvhXvfDTevgjrVN7rCEHR/WG1yHn4L9r+iXuuxz9O/6MdA5kZhtWWenDm4Pf1hWnoDpumHs5M2Ro1pQk9vbmVWbUli0xQp4bHPQ/c+WPZ+WP8HaHkLJmfwaZ/7oYpso0G4bGTKoQ2Se7osK66kuTvAyTMnQft2FUmXNahKY3c5uMvA1w4bH1TVxQsuVrnoPQHeSt4QfepL6nE3Pq1yk5NZfIXyaF/8b3VinjVy3qkpR/bC3z8B+14CZzGc8H5YeRO8dju89FOoaoITP5z+vLAfXohfKXbtVgV2Bq5S9ZxTP6G853zwtsK2x2DLo6q6MhaGiukweYmqH6lfBD0H1H17X4ZgPBNkzrlwyq8Rs8/h5Z++wFx/Kbznf/l2y6lccPAXXNryC7j9Gbj+yfSTja8Tdj+XCCrcDjv15dlz0X3BCNtbvaYVyLNqShK9WlLp8Yfp9IUGtc0dbcanoANMWQYRP5z8Mdwb3sw4gm6QfZGDwILLuWy1jX9U3o793ktxr/wGcFzmSsH9rw10bSxrgIWX4nHaB9oQrP4tBHrgjC/Sd1fnQJZL3XFw3ePw0+PhlZ8nhM4Q9B5/fPNm7V1q93zlR2DVz6koPh2YnLGVb125mzeSBkOYYWyIzjNJAUtOXVw5cxI9/jCv7OrkhtNnDjxo/R9hw1/h7G/ASTfCW/erP2aC3t8Fmx9WfvO6+1Qx13GXZF3f0ZCci754agUtvQGmldvhwevVzzGp4AxQexktG+Gp/4A55zKl0sOm5p6BDdEj25VfftJH0sXc4OIfK2F86Ca4+WUoqRmx40vjmW+rKPf876u0OiMavvgnSjgf/TxUNCrBNGjbCg9cB22boXElzDwTJs2CSTOheJL6/b76a3VSWPJeOO3TiYDDFClVUsGrt6mfA1K93ik3q9c7/JY64W99jMRs+aqZcPy71Umw6XRISmYwctFf2N7OPbtKmXzhXZxWvxXu/6D6PV32i8Hvv+URdSWw6PLETY1VxVkj9LcO9hCTcILJ0JKZNaW8ursLKWWaxWPszzRVa0Efft75PxD2gbsUj8O8fwooQS+yKOj15R52yEZeOvt+zt16C5Nf+x4rxLcodZ9s/oTnf6i81MoZ8PeboWYuRU4HoWiMiN+L45VfqC/TlBPwBZ8YbJWUVKsv4Rv3wDnfgrL6RE/0Xn9EWQJv3Q/HXw7v+DbsW8WSN79LLT/IGKHXlbnp8oUIRWK4MqRqGoK+wETQp1YWUeS0JzZGn9vWRiQmB+yW9u3wzy+qL+HpXwCbHeZdoAT+vO+q/yez/o8qMn///fDIp1X74mkrodRabnm+qGk+6rK4zasmEF3UepuyJK7+y2AxB+V7n/99+OOVsOZ3TK44l46+EOsPdHPW3BrVnMldDmd9NfObukrgyrvgN++Av388Yd9YQkoVIR9er8S1clrOpyQ4sledLE/7lPqTelxX3g13XgT3fxiuf0JdmbxxLzz+FbXmDzw4WOgNZp+j9kVe+aV6/Po/wtL3wTn/oU4OyfS1wWNfUKJaMx/O/rpKAzaa4CUT7IO2LUq8K6dnPKyplR42Hurhe49uZkZ1Mde9fSY45qgTy8v/C8f/P5jzjoEnbPobTJoNDUsSN02rKho08SqV5ArRVGbWluAPR2ntDaZVKCeaco1hhF4guyJDoKxeRQKozJKgiaBLKfGHLXjoceorlDfa7HfA5XcQKKrn2857KXGafEH3v6Z21t/2GVUq7CyGP19DhVBiGF1zD/R3whlfIhaT5hWep9wM0TC8fgeQEqG/dT+E+lRapd0B7/419qif/3L+jmJX0vHEYvDmn+EXK1nhU02E2k0m7xhsa+mlzOMwzRiw2QSz60oSPV2e2txKTalbRTLhgPLNHR64/I4B8V7yXpVttOf5wS8mpYpuG1cqi+ny36gv9cOfHNiMzEYkBM/+AHY8k/uxcYzhxHs7fTR3+znbto4Fe++Dkz8G8y80f9Lc85SIPfdDphepn1uXL8SFnrdg97NKzItz9K9pWAzn3qL6AqU0ckrjyD5ld/zxKrh1Nvx8ufq53nEmHH7T8rHy6m2qMvrkj5nf7y5TJxd3KfzxvWqwyz8+DdNPVlcSZmJuUDVDXXl8bpP6fG98CH5+osrQCnrV72/jg/DLk2H7E8qrv3kVnPlllVVidkJzl8K0k7KKOcCUiiK6fCF2tPXx9YuPGxhqctbXVDbaI59WViaoE8reF1V0nvSejVXFNHcHMg5sefNAN9MnFSf2iZIxOijuNsl02d3uQwhyDhkZScavoCehOhym//KMLJVSt7Ud6JoSN3abUMVFrhI2H/9FFtn2Mnn3A+kPNqLzk25UXuNVv4fuA5y35Rt4COJ47ecqkp1+Cv1ho9NiSgRbPVtZEKt/CyFfYlO0pz+kNooaFg9c6tfOZ9WMj3OefS0lW+LrObgW7jwf/vZR6NzB0t13ADKtwVgy21v6mJ/cE2PPi/Dv7yfun1Nbys5WL8FIlOe2tnHewjqVJfLMt9WA7nf/erC3OvcCcFeoE1Aye1+Czh1qwxnUZft531Git/buLL8F1EbkvZepn/ED10Pv4eyPT2JmfARbR8t+fuK8jUD1Qjj3O5mfIITKIQ72snL/bwBwEOH03f+rqpJPutHaG6+4AUpq4dVfZX5MNAz3Xgr//p7aLJ53Ibzr/1QmhrMY7n6XChRy4T+ioufFV2b3uSumwjX3K9tvyz/gHbfAB/6Wll2VkZJq9Tv75GoVeb/4EzXt677L1e9l0kz46IuqoG+YsnyMXPTTZldz/sKkzUenBy77FXib4elvqds2PwwypqL2JBqriojGZMY2FkaHRTMGUhfTffQ39h9hWlWxZQt3JJgggm4nYDKxqD2ek11Tam1quc2mBkUY1Zbbay9gdWweNa//SKUPGiRH56745df0U+DiW5na8TIPuL6Dva8FzvgiMFAQZHpiOe3TEOiGdX9IROjFbW+oStgVNwyKPFbVXMkaOR/7k1+Fhz4Kvz1HRXyX/Qre+d+U9WzjRLE9Yy66lJJtrd4B/zwcUDbBC7eqS3hUpktzT4BnNrfhC0WV3RLsUyeYEz6QHuk6PXD8ZUowQkkbUWvvAk/F4C/byo8qz/bJrytBM6NlA9xxNjS/oWycaFBd1meK6vvaVVO2p78Fr93ORY41eDo2cPyrX6aYINH/91u1xmzUL4Tl1zJ5+33MEs180PEMRb27ldBbTUdzetTva/sTmY9tw1/Vz/mqP8Cn1sC7f6U2IGedpfZUSmpU69Zdz2Z/rzV3Kbvx1E/kXtfkJXDDU/DRF1SGzlBSGatmqIysG/+tTnJ7X1JR+fVPZffXh8AJ0yuZXVvCLe86Pj1NcdpJcMrH1Wdr93Ow6e/K6qlbOOhh2fqiH+7x09IbyCjoDeUePE5b2sbozrY+XtzRwRUnNpo+b7SYGILusJt66MbQ35qy3IUlBvXlA8VFfaEo3wl/CJu/S4meQXJ0nsyK69jX9F4W2fbirztBiRdJY+zMNjOnrVS2xKu/xCkkxS478w/eD64yFYEl0ReWfM/+KZU9sPFBdUL51FqV3bDkKmLucj7keDqjoLf2Bunxhwf889dvh554YUy898WcOnXfbc/vosRl59TZ1cp6iAZhyVXmP7TF71X20LZ/qv/7OmDzI7D0anAmVWnabCrCtzvhD1eqK4PtTw2UZ2/5B/zuAnV81/1THd/ZX1eZE5seSn/fYB/84QplWb36a3j8y7x/79f5C1+l8chr/EhcR0nj8eZrTuXsr4PDw3cdd/E5x0NKZOddYO25BiuuB7tLZTalEosqq6V+MSx4Z/r9ldOUqFfNVBbJ1sfM3yMSUhuWs85WV3BWqD9+INX3aGg8Ua3xK3uHNSpPZlZtKf/6wlmZ+7ac8x/KM//bzbDv5TS7BUgMkTYT9FU7OwE4OUMbaJtNqFbMKRH63av24HLYuObk7JbRSDMxBD2D5WJE6LUWKgUNGso9iUu1/lCUjXIWctkH1Je0fTsceD09Ok9i14pvcVvkEg6c+v3EB+3v61Ra2IxMu+OnfUpFblsfpdEd4Liuf8PSq5TvmER/MEqXZyrc+IyK8M777kBut6sEll7DRbbX8HUcSn8PkjJc6stUutcL/63aDdfMg+2PAwM9XTYc6uHM+bXq8nLbEyrann6q+fpnvA3Kpw7YLuv/oET5xOvSH1sxFd5zp1rvi/+jNiR/PBN+thz+8gG1oXbTcwNW0ymfUB78P7+s1mwQCanMh5YNKuL9Rit8cQevn/cgHw19jk/avsGrFSbCmYnSOsQZX+Tt9k2U0g8X/Jf1zU2DsnpYdAWs+8PgKzpQPnTXLjjzS5lft6wePvyoEuq/fFANNU9l4wPQ15K+ETpaCGH6uR81nEUqK8x7GJBpdguo3vZCYJq6+PLODiaVuDiuIXNNxOza0kG56N39IR5ce4h3L5tiqep4JJkggm4eobf3qSY/tXlE6A1J5f9Gh0Tbubcoj/PJr6u8arPo3FiLp4gfRq6hq0J1udtwsIdfPbeLy5dPzXiZx4J3qsjs5Z9xhf15nDKkor0U+oxhG/XHqxzjFGwrb8QlojQdMIlmUQVFEG/K9cKPVWHNed9TXu7elyHQy4zqYhzxysrzFzaoyHL7E0r4M9kPNpu6mtj5jNqoWnu3Ev9Ml+Nzz4WPvQhfOwDXPqqyKmrmwsk3w4cfG+zx2h3qCxzogSfiU2BiMXj4E+rEeunPlA1ks0FpHdXzTuHJ2Ek82n88U6ry3Lw6+WYCNYsInvRx9TMeCqfcrOyQpPGGxGLqCq/2OFjwruzPL56kPPVZZ6pNzMe+qLx3ULbTqp9D3fFqI3eiMuNUtQE7/2LTwh63w05DuSctQpdS8tLODk6bXZ21a+jMmhL2d/UTjm+q/nn1AfzhKNe9bWbG54wWE0LQ3U47wUgsre1muzeIEJjuZmeirtyNNxChPxQZ6JBYWgtnfkU14dn1r4zROah+6KA2ZEORGF/865vUlLq45ZIsAmGzKz/00BquCd7PVtdCU0HpD0VN54kmqJnLOsdSTur4u2mPla0tXurK3FQFDqiN2OXXKtGdf5GKqHf9C6fdRlNNCQ6bUK1rD65RVZLzMmSJGCy5SuUDP/o5lYpnFp2n4iqBmaervYZr/gIX/dDc764/XqVJbvirulp45luqWOmcbypfP4lpVap8G6x1WRyE04PnEy9R9M7/zO95yUxeojbDX79joGfPloehY5s6TisetrsMrvkrnPpJWP0b+P3/U1cnu/6l8sdP+2T+Vw/jjbO/Dlf/KePdjVVFaaPodrT10eYNcvrc7LUCM2tKiMYkB+Kifs+qvZw2u5rjJo/9KMIJIehGWmIwpbiooy9IVbErr9FbRjpfS08gPtwi7hOuvAmq50JxTdbMByPnPRCK8vN/72Bbq5cfXL6YiuIcm2vLroGiKkplH484LjJ9iGoUlt23fLnqMqqj7SqqTmF7q1d5k8/cotIPz/qauqNxpSpKifvoFy1q4MoVjWrN2x9XPeOzpbmB2lisXwxbH1WvtfCy7I/Pl9O/oDa/HrheRaknfUTdloLLYUtsilnpg57GcAjlKTerwp6t/4hH5z9Rnx0TeyAjdgdc8J/w/25XNt9vzlJ7DmWTla2jyYpZcdFLOzoA1VI4G0Yl6J4OH09sbOFwT4Drj4HoHCaKoDuMQdGDo9J2bzAv/xySBL03oCwOQ0AdLrUh9JF/ZfUQDUF/fW8Xv3puF+9Z3sg5Cyy0nXWVwNs+Q6ezgcejK00fkmlAdDKH6s6mlUmJ0XoG0Zhke6uXc4t3q83Ht312oELP7lCWyo6nIBblC+fP5weXxws1tj0OM06z1t9jSXwTd+k1uTNL8sXhUlWC0SAcdylc9KOM4muknllpmzsizLtQWWiv/lqdEFs3xqPzIaS7LX0fXP+4sl2a16mufg7rV5wTlcaqIlp6B+eiv7yzg6bq4sQJPxOzklIX73x5DzOqizlnwcgUw+XLxBB0IyoOp0foNWX5ffiNFrFtvcH4gOikL2Fpral3nYzRe/3uVXupKXXxrUsWZn38IN7+OX6x5CE6AuZC5QuZD4hOpqaihD9EzkmM1jPY39VPKBLhktZfqlmqqSlv8y4Ef5eKBg26dkP7VuVVWmHZ++G4d6kIdSSYeqIqdrnynqziaAj6kCL04cBmVwU/B15THnjVzKOLqqeeqDaKz/22ulLU5MTIRTcGf4ejMV7d3ZkzOgeoLHZRVezk7+sPsW5/N9ed1jSqk7qyMUEEXR1maoTe0TeECL1iIEL3BXNbHOlrUUIjJdaslhTKPU68wQjRWHretS9oPiA6mboyN3+KnI2Mj9YDwH8E3yu/48+u71PdvUF1BnSlRClz3qGslXi2CzAwxiuXf25QUgNX3ZdfCXu+lDXk9KHn1pcihPLTx4wT3q/aBniblTV0tCl+ZQ0qVXAsM0wKiNRc9PUHuvGFojn9c4OZNSVsPNRLmdvBFStG8POcJ+O3l0sSiQg9qbhISkm7N5h3mlGp20Gp20FLTwBfKEpjVX4/wmKXnWKXnYsXT7ZmtaRgFBd5A2EqiwdfXfhC0ZwRem2Zh3aq6Gm6iMp1v1dtUXc8xaJYmN1MJnz2LTiXvC/9iZ4KlX647QmVDgkqr7z2OFURWEBccWIjCxrK0npxjCruMnUVtOUfyjbRjCrTEoLeD1Tz0o4OhIBTZ1kT9Fm1pbyxv5urTpqWc3TkaDLBIvQBy8UXihIIx/JKWTSoL1d9xX3BSPasEhOcdhtPf/5Mfni5xaKPFNI6LsYZGBCdI0KPj6LbNfMalerX/Aac/FF+MO02ri/9Fc4zs1QLzr9IZWN07Vbl5ftWqdsKDLfDzokzcvRfGQ3O+qrqmzJKww80AzRUeLAJOBCP0F/e2cGSqRWWr5iPm1yO0y649rSmEVxl/hw7p5YRxGxTdKDsfyiC7qGlJ2VTNA+OZjMuMeTCP3gUnTEgOtd66uInsB3uRZz4uU0qK8Jm55n/fo55DVlmMoKyVp74qorSS+tUGmIBCrpG43LY4rno/XgDYdYd6OajZ8yy/PwPnDKd8xfWM20MG3GZMSEidLczXdCNsv+hROgN5R5ae4P0h6KjfrmVKUI35omajZ9Lxjje1t6gandqU0VXezv7TVvmDmLSTDVibfvjym4pqc3cB1yjOcYxUhdf291FNCZ5u0X/HNRV3rEm5jBBBN3McjmqCL3Cw+EeP9GYHFKEfjSUF6n3SxV0Y56o2YDoZNwOO1XFzkGj6Ha19xGNSdOhFmnMu1BZLTueVr1MhpJqp9EcAzRWFXHoiJ+XdnbgcdpYPj3DOLwCYoIIuhKdYGR4IvT6MjdGkolpQ60RpCJprmgyRsfGXBE6QF2ZZ1CDru2tSSX/uZh/kRpKHexVE4Y0mgKlsaqIwz1+nt/ezklNk8a07e1wMaEEPdVDt+VZ9m+QnB2RaxNyuMlkufjilkvGcXhJ1JW7Bwn61hYvrnhJf04aT1K9auxumH12HivXaI4tGquKiUlVIPR2C/nnhYAlQRdCXCiE2CaE2CmESJu3JYSoEEL8QwjxphBikxDCQqOO0cPjSLdcOvqCTIoPrMiX+qRpPqNtuRQ57ThsIt1DDxqbormjjNoyN+1Jzf23t3iZVVtirQWCza56tJ/6cZ3zrCloGicNJCdYKSgqBHKqkRDCDvwSOA84CKwWQjwipdyc9LBPAJullO8SQtQC24QQf5BShkZk1XmSKUK3OtgilcGCPrqXaUIIKoqc9GaI0K2cYOrKPLT3BRODbre1eFk5M480vrd/Np8lazTHJEYu+qQSFwuPgcZaw4GVCH0lsFNKuTsu0H8GUjsrSaBMqBEipUAXEOEYwaz0v70vNCT/HFSEa7QJGe0IHZTtkp7lEo/QrVguZW7CUcmR/jC9gTDNPQFrG6IazTiiocKD3SZytsstJKyo0VTgQNL/DwKpY+5/ATwCNANlwFVSSvMJrGOA3SZw2sWgStEOb5DZVjxjE5x2GzWlbtq9wTGpEiszEXRjUzRXpSgMXGG0eQP0BdTzcqYsajTjDKfdxq1XLGHx1IqxXsqwYSVCNzt1pTYSuQBYD0wBlgG/EEKkXcMIIW4SQqwRQqxpb2/Pc6lHR/IYOikl7X3BvEbPpWJ0XRyrCL03MPgCKJG2aGGn3qgWbe0NDp5SpNFMMC5f3sjccfTZtyLoB4Hk7jONqEg8meuAh6RiJ7AHSBtHI6W8Q0q5Qkq5ora2dqhrHhJupz1huXiDEUKRWN6NuZKpj4uilTTB4cbMQ+8PqelJDgsbm0a1aFtvgG0tXkrdjrFrJavRaIYNK4K+GpgrhJgphHAB70PZK8nsB94BIISoB+YDu4dzoUeLx2kjGI/QE0VFebbOTaZ+DCP0co/DNG3R6lrqygzLJci2Fi/z6kvTJ6hrNJqCI6cCSCkjQohPAk8CduBOKeUmIcTH4vffBnwPuFsIsQFl0XxFStkxguvOG4/TnvDQOxLDoYfebe/0ubU0d/vzmnY0XBgRupGlAvHhFhYzbopcdsrcDtq9ynK5aNHkkVyuRqMZJSyFdFLKfwL/TLnttqR/NwPnD+/ShheP05awXNr7jj5Cv3BRAxcuasj9wBGgoshJJCYHjcDzhXL3Qk+mttzNxkM9dPeHmV+foymXRqMpCCZEpSgM3hQdiNCH7qGPJeUm5f++YI4B0SnUlblZd6AbgPkN4yMHV6OZ6EwcQXcOCHp7XxC7TVBVXJizF83K//Px0EHtARhTj+brlEWNZlwwgQR9wHLp8IaoLnEVbDFBuScu6P0Dgt4/hAgdVJHUUPrZaDSaY48JI+jupE3R9r78R88dSwx0XBzIRc/XQzcyXSx1WNRoNAXBhBF0j8NO0IjQ+4JDLvs/FjCzXJI3SK1gFBfpgiKNZvwwcQTdaRvw0IcwHPpYwmzIRV8wYqns38A4oemSf41m/DCBBF1tikopCz5CL/MYc0WVoFsdEJ3M8ulVfPi0Js5bWD8ia9RoNKPPhBgSDfFK0UiMHn+YcFQOuXXusYDdJihLqhY1Oi3msynqcdr59qXHj8j6NBrN2DBxInSHnUhM0hIf7FDIETqoTJfehKBb74Wu0WjGLxNH0ONdCA92+YHCLSoyUB0XlaAnOi2OQaMwjUZz7DCBBF0d6sEj/QBH1Tr3WCB5yIURoY9Fb3aNRnPsMGEE3R2P0A8cGR8RennRgIfeF7Q+IFqj0YxfJoygJyyXI/04bCKRy12oqI6LSsjzGRCt0WjGLxNH0B3qUA90+akpdRds2b9BuWfAcjEGROsIXaOZ2EwcQU+K0I+mbe6xQkWRE384SigSGxgQrSN0jWZCM+EEvTcQKXj/HKCieKCFrk976BqNhgkl6AOHWshl/waJjov+cCJtcSzmm2o0mmOHCSToA2JX6EVFkNRx0R/Oa0C0RqMZv0wYBfA4BgR9XEToSR0X8x1uodFoxicTR9CTLJfxEaEPdFzMd7iFRqMZn0wYQXc7x2eE3huI5D3cQqPRjE8mjqA7xleEXu5J9tCjefVC12g045MJJegiXks0HtIWPU47boeNHn+YvmBE93HRaDQTR9CFELgdNlx2W2LiT6Gjyv+1h67RaBTjQ9ks4nHaKXbaEaKwy/4NjI6L2kPXaDQwgSJ0UKmLhd42N5nyuKBrD12j0cAEE/Qil31cZLgYGEMufEEdoWs0mglmuXzpgvnjIsPFoNzjYOvhEMFITBcWaTSaiSXoFy+ePNZLGFYqipy0eoOAHj+n0WgmmOUy3qgochKNSUAPiNZoNFrQC5rypKlLOkLXaDRa0AuYZEHXm6IajUYLegGTPBdVpy1qNBot6AWM0c8F0KX/Go1GC3ohMyhC15aLRjPh0YJewBhzRUEPiNZoNFrQC5pyz0BUriN0jUZjSdCFEBcKIbYJIXYKIb6a4TFnCSHWCyE2CSGeH95laswodTuw21SjMZ22qNFocoZ1Qgg78EvgPOAgsFoI8YiUcnPSYyqBXwEXSin3CyHqRmi9miSEEJR7HPhCUZx6QLRGM+GxogIrgZ1Syt1SyhDwZ+CylMdcAzwkpdwPIKVsG95lajJRXuTUGS4ajQawJuhTgQNJ/z8Yvy2ZeUCVEOI5IcRaIcSHzF5ICHGTEGKNEGJNe3v70FasGURFkVPbLRqNBrAm6GbTIGTK/x3AicA7gQuAbwoh5qU9Sco7pJQrpJQramtr816sJp1yjxZ0jUajsHKtfhCYlvT/RqDZ5DEdUkof4BNCvAAsBbYPyyo1Gbnx9Jn0BiJjvQyNRnMMYEXQVwNzhRAzgUPA+1CeeTIPA78QQjgAF3Ay8NPhXKjGnLPm6/1njUajyCnoUsqIEOKTwJOAHbhTSrlJCPGx+P23SSm3CCGeAN4CYsBvpZQbR3LhGo1GoxmMkDLVDh8dVqxYIdesWTMm763RaDSFihBirZRyhdl9OnlZo9Foxgla0DUajWacoAVdo9Foxgla0DUajWacoAVdo9Foxgla0DUajWacMGZpi0KIdmDfEJ9eA3QM43LGgkI/Br3+safQj0Gvf2jMkFKa9k4ZM0E/GoQQazLlYRYKhX4Mev1jT6Efg17/8KMtF41GoxknaEHXaDSacUKhCvodY72AYaDQj0Gvf+wp9GPQ6x9mCtJD12g0Gk06hRqhazQajSYFLegajUYzTig4QRdCXCiE2CaE2CmE+OpYrycXQog7hRBtQoiNSbdNEkI8LYTYEf+7aizXmA0hxDQhxLNCiC1CiE1CiM/Eby+kY/AIIV4XQrwZP4bvxG8vmGMAEELYhRDrhBCPxv9fMOsXQuwVQmwQQqwXQqyJ31Yw6wcQQlQKIR4QQmyNfx9OPdaOoaAEXQhhB34JXAQsBK4WQiwc21Xl5G7gwpTbvgr8S0o5F/hX/P/HKhHgC1LK44BTgE/Ef+aFdAxB4Bwp5VJgGXChEOIUCusYAD4DbEn6f6Gt/2wp5bKk3O1CW///AU9IKRegRmxu4Vg7BillwfwBTgWeTPr/14CvjfW6LKy7CdiY9P9twOT4vycD28Z6jXkcy8PAeYV6DEAx8AZqTGLBHANqlu+/gHOARwvtcwTsBWpSbiuk9ZcDe4gnkhyrx1BQETowFTiQ9P+D8dsKjXop5WGA+N8FMRhUCNEEnAC8RoEdQ9yuWA+0AU9LKQvtGP4X+DJqxKNBIa1fAk8JIdYKIW6K31ZI658FtAN3xW2v3wohSjjGjqHQBF2Y3KbzLkcBIUQp8CDwWSll71ivJ1+klFEp5TJUpLtSCLFojJdkGSHEJUCblHLtWK/lKHiblHI5yi79hBDijLFeUJ44gOXAr6WUJwA+xtpeMaHQBP0gMC3p/41A8xit5WhoFUJMBoj/3TbG68mKEMKJEvM/SCkfit9cUMdgIKXsBp5D7WsUyjG8DbhUCLEX+DNwjhDiPgpn/Ugpm+N/twF/A1ZSQOtHac/B+JUdwAMogT+mjqHQBH01MFcIMVMI4QLeBzwyxmsaCo8A18b/fS3Klz4mEUII4HfAFinl/yTdVUjHUCuEqIz/uwg4F9hKgRyDlPJrUspGKWUT6jP/bynlByiQ9QshSoQQZca/gfOBjRTI+gGklC3AASHE/PhN7wA2c6wdw1hvNgxhc+JiYDuwC/jGWK/Hwnr/BBwGwqiz/A1ANWqDa0f870ljvc4s6387ytZ6C1gf/3NxgR3DEmBd/Bg2At+K314wx5B0LGcxsClaEOtH+c9vxv9sMr63hbL+pONYBqyJf47+DlQda8egS/81Go1mnFBolotGo9FoMqAFXaPRaMYJWtA1Go1mnKAFXaPRaMYJWtA1Go1mnKAFXaPRaMYJWtA1Go1mnPD/AUhR9+KwJi0IAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(overlap_train_scaled.shape)\n",
    "print(overlap_test_scaled[0].shape)\n",
    "print(imask_test[0].shape)\n",
    "\n",
    "\n",
    "x = overlap_test_scaled[0].reshape((1, 64))\n",
    "y = imask_test[0]\n",
    "yhat = NN_model.predict(x)\n",
    "\n",
    "x_axis_list = list(range(0, 64))\n",
    "plt.plot(x_axis_list, y)\n",
    "plt.plot(x_axis_list, yhat[0])\n",
    "plt.title(str(\"NN\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d217fa05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
